[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT 326 Labs and Projects",
    "section": "",
    "text": "Site Information\nWelcome! This site contains code and exercises for the labs in STAT 326 (Mathematical Statistics), information for the mini projects in the course, and information about the final portfolio. While we will also do plenty of handwritten work to help understand concepts, the primary purpose of this site is to hold all of the computing/coding work in one place.\nThe syllabus for the entire course is also given here.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#instructor-information",
    "href": "index.html#instructor-information",
    "title": "STAT 326 Labs and Projects",
    "section": "Instructor Information",
    "text": "Instructor Information\n\nProfessor: Matt Higham\nOffice: Bewkes 123\nEmail: mhigham@stlawu.edu\nOffice Hours: 15 minute slots bookable at https://calendly.com/mhigham/prof-higham-office-hours. The link to book is also on our Canvas home page.\n\nNote that you must book a time for office hours at least 12 hours in advance to guarantee that I am present and available at that time.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#course-materials",
    "href": "index.html#course-materials",
    "title": "STAT 326 Labs and Projects",
    "section": "Course Materials",
    "text": "Course Materials\n\nCourse Notes\n\nPrint out and bring to class.\nFolder or 3-ring binder to keep notes in.\n\nLaptop\nTextbook (free at https://ebookcentral.proquest.com/lib/stlawu/detail.action?docID=7103761 with institutional log-in).",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#general-course-outcomes",
    "href": "index.html#general-course-outcomes",
    "title": "STAT 326 Labs and Projects",
    "section": "General Course Outcomes",
    "text": "General Course Outcomes\n\nGiven a probability model, derive a point estimator for parameter(s) in that model using data.\nDescribe properties of what might make an estimator “good.”\nGiven a probability model, derive an interval estimator for parameter(s) in that model using data.\nExplain the difference between a “frequentist approach” to statistics and a “Bayesian approach” to statistics. Apply a Bayesian approach to analysis to binomial data and to count data.\nDerive and conduct hypothesis tests about parameters in a probability model using classical statistics tests and simulation-based permutation tests.\nUse statistical simulation to answer questions about how statistical methods work and how violations of assumptions of statistical methods impact results.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#use-of-r-and-rstudio",
    "href": "index.html#use-of-r-and-rstudio",
    "title": "STAT 326 Labs and Projects",
    "section": "Use of R and RStudio",
    "text": "Use of R and RStudio\nWe will use RStudio throughout the semester as a tool to help us understand concepts in this course.\n\nR and R Studio are both free to use.\nYou should already have both R and R Studio installed on your personal computer from MATH/STAT 325.\nThe purpose of this class is not to learn R in detail. The concepts for the course receive a strong priority.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#assessments",
    "href": "index.html#assessments",
    "title": "STAT 326 Labs and Projects",
    "section": "Assessments",
    "text": "Assessments\nThere will be 5 100-point assessments throughout the semester, given on Wednesdays. More details about what you might expect on these assessments will be provided closer to the date of the first assessment.\nAdditionally, 100 points will be given to the average of your highest 4 assessments. Therefore, the total number of points from assessments will be 600 points.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#mini-projects",
    "href": "index.html#mini-projects",
    "title": "STAT 326 Labs and Projects",
    "section": "Mini-Projects",
    "text": "Mini-Projects\nOn many of the Wednesdays on “off-weeks” (weeks where you do not have an assessment), you will complete five different mini-projects. The topics of these mini-projects vary widely from project to project, but, by the end of the semester, you can expect to have completed statistical simulation studies, a meaningful story, a Bayesian data analysis, and an analysis on the benefits and drawbacks of using p-values in statistics.\nEach mini-project will be worth 30 points, for a total of 150 points.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#homework-assignments",
    "href": "index.html#homework-assignments",
    "title": "STAT 326 Labs and Projects",
    "section": "Homework Assignments",
    "text": "Homework Assignments\nWeekly Homeworks are worth 10 points each and are due most weeks on Mondays. Homeworks will be graded for both correctness and completion, though you will be given “checkpoints” on each homework problem so that you can check your work as you go along.\nOne homework will be dropped from your grade so the total number of points from Homework Assignments will be 90 points.\nYou may work with other students on the homeworks, but please make sure to read the Rules for Collaboration section before doing so. If you need additional help outside of collaboration with classmate or office hours, the Peterson Quantitative Research Center (PQRC) in Valentine Hall is a great resource!",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#recap-tasks",
    "href": "index.html#recap-tasks",
    "title": "STAT 326 Labs and Projects",
    "section": "Recap Tasks",
    "text": "Recap Tasks\nIn addition to homework assignments, you will also be assigned “recap tasks” to complete by the start of class every Monday. The purpose of these recap tasks is to give you additional practice on concepts discussed in class. Each recap task is worth 5 points. There will be 13 recap tasks throughout the semester, and one recap task will be dropped from your grade. Therefore, there are 60 points to be earned from these recap tasks.\nYou may not use AI on recap tasks, unless otherwise stated.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#final-portfolio",
    "href": "index.html#final-portfolio",
    "title": "STAT 326 Labs and Projects",
    "section": "Final Portfolio",
    "text": "Final Portfolio\nA final portfolio will be assigned near the end of the semester. A component of your final portfolio will be answering some questions about it in person so you should make sure that you are around for our final exam the morning of May 6. More details will be provided later, but the total number of points for this final portfolio is 100 points.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#point-allocation",
    "href": "index.html#point-allocation",
    "title": "STAT 326 Labs and Projects",
    "section": "Point Allocation",
    "text": "Point Allocation\nThe 1000 points possible for the class will be allocated in the following way:\n\nAssessments: 600 points: 100 points for each of 5 in-class assessments, plus 100 additional points for the average of your top 4 assessments.\nMini-Projects: 150 points: 30 points for each of 5 mini-projects, none of which will be dropped from your grade.\nHomework Assignments: 90 points: 10 Homeworks for 10 points each for a total of 90 points (with one of the 10-point homeworks dropped).\nRecap Tasks: 60 points: 13 recap tasks, each worth 5 points, with one recap task dropped from your grade, for a total of 60 points.\nPortfolio: 100 points: 1 final portfolio. Details of what will go in your final portfolio will be described later.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#grading-scale",
    "href": "index.html#grading-scale",
    "title": "STAT 326 Labs and Projects",
    "section": "Grading Scale",
    "text": "Grading Scale\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrade\n4.0\n3.75\n3.5\n3.25\n3.0\n2.75\n2.5\n2.25\n2.0\n1.75\n1.5\n1.25\n1.0\n0.0\n\n\n\n\nPoints\n950-1000\n920-949\n890-919\n860-889\n830-859\n800-829\n770-809\n750-769\n720-749\n700-719\n670-699\n640-669\n600-639\n0-599",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#rules-for-collaboration",
    "href": "index.html#rules-for-collaboration",
    "title": "STAT 326 Labs and Projects",
    "section": "Rules for Collaboration",
    "text": "Rules for Collaboration\nYou are allowed to collaborate with your classmates (or your classmates from the other section of this course) for homework assignments and handouts with the following rules.\n\nyou must state the name(s) of who you collaborated with at the top of each assessment.\nall work must be your own. Even if you work with someone else, you must write your answers on your own. Therefore, I expect your answers to free response questions to be at least slightly different from the person(s) you collaborated with.\nyou must not copy answers directly from the Internet or directly from the homework solutions file.\nthis isn’t a rule, but keep in mind that collaboration is not permitted on any of the exams. Therefore, when working with someone, make sure that you are both really learning so that you both can have success on the exam assessments.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#ai-policy",
    "href": "index.html#ai-policy",
    "title": "STAT 326 Labs and Projects",
    "section": "AI Policy",
    "text": "AI Policy\nThroughout the semester, we will use generative AI (specifically, ChatGPT) to aid us in performing basic calculations and in evaluating integrals. For homework assignments and mini-projects, the policy on AI usage will be stated at the top of the assignment. For recap tasks, you may not use AI to assist in coming up with your answer. Make sure that you follow this policy. While AI can be a tool to enhance your learning, becoming overly reliant on it prevents the growth of logical thinking skills.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#diversity-statement",
    "href": "index.html#diversity-statement",
    "title": "STAT 326 Labs and Projects",
    "section": "Diversity Statement",
    "text": "Diversity Statement\nDiversity encompasses differences in age, colour, ethnicity, national origin, gender, physical or mental ability, religion, socioeconomic background, veteran status, sexual orientation, and marginalized groups. The interaction of different human characteristics brings about a positive learning environment. Diversity is both respected and valued in this classroom.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#accessibility-statement",
    "href": "index.html#accessibility-statement",
    "title": "STAT 326 Labs and Projects",
    "section": "Accessibility Statement",
    "text": "Accessibility Statement\nYour experience in this class is important to me. It is the policy and practice of St. Lawrence University to create inclusive and accessible learning environments consistent with federal and state law. If you have established accommodations with the Student Accessibility Services Office in the past, please activate your accommodations so we can discuss how they will be implemented in this course.\nIf you have not yet established services through the Student Accessibility Services Office but have a temporary health condition or permanent disability that requires accommodations (conditions include but not limited to; mental health, attention-related, learning, vision, hearing, physical or health impacts), please contact the Student Accessibility Services Office directly to set up a meeting. The Student Accessibility Services Office will work with you on the interactive process that establishes reasonable accommodations.\nColor Vision Deficiency: The Student Accessibility Services office can loan glasses for students who are color vision deficient. Please contact the office to make an appointment.\nFor more specific information about setting up an appointment with Student Accessibility Services please see the options listed below:\nTelephone: 315.229.5537\nEmail: studentaccessibility@stlawu.edu\nWebsite: https://www.stlawu.edu/offices/student-accessibility-services",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#academic-integrity",
    "href": "index.html#academic-integrity",
    "title": "STAT 326 Labs and Projects",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nAcademic dishonesty will not be tolerated. Any specific policies for this course are supplementary to the\nHonor Code. According to the St. Lawrence University Academic Honor Policy,\n\nIt is assumed that all work is done by the student unless the instructor/mentor/employer gives specific permission for collaboration.\nCheating on examinations and tests consists of knowingly giving or using or attempting to use unauthorized assistance during examinations or tests.\nDishonesty in work outside of examinations and tests consists of handing in or presenting as original work which is not original, where originality is required.\n\nClaims of ignorance and academic or personal pressure are unacceptable as excuses for academic dishonesty. Students must learn what constitutes one's own work and how the work of others must be acknowledged.\nFor more information, refer to www.stlawu.edu/acadaffairs/academic_honor_policy.pdf.\nTo avoid academic dishonesty, it is important that you follow all directions and collaboration rules and ask for clarification if you have any questions about what is acceptable for a particular assignment or exam. If I suspect academic dishonesty, a score of zero will be given for the entire assignment in which the academic dishonesty occurred for all individuals involved and Academic Honor Council will be notified. If a pattern of academic dishonesty is found to have occurred, a grade of 0.0 for the entire course can be given.\nIt is important to work in a way that maximizes your learning. Be aware that students who rely too much on others for the homework and projects tend to do poorly on the quizzes and exams.\nPlease note that in addition the above, any assignments in which your score is reduced due to academic dishonesty will not be dropped according to the homework policy e.g., if you receive a zero on a homework because of academic dishonesty, it will not be dropped from your grade.",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "index.html#pqrc",
    "href": "index.html#pqrc",
    "title": "STAT 326 Labs and Projects",
    "section": "PQRC",
    "text": "PQRC\nThe Peterson Quantitative Resource Center (PQRC) offers free, no appointment necessary peer tutoring across a range of courses with quantitative content. The PQRC student staff of mentors is trained to assist students to develop and to improve their quantitative skills and understanding. More information about the PQRC’s current hours and modes of operation can be found at the PQRC webpage: https://www.stlawu.edu/offices/pqrc",
    "crumbs": [
      "Site Information"
    ]
  },
  {
    "objectID": "samp-dist.html",
    "href": "samp-dist.html",
    "title": "1  Sampling Distributions",
    "section": "",
    "text": "Lab 1.1: Introduction to Statistical Simulation",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling Distributions</span>"
    ]
  },
  {
    "objectID": "samp-dist.html#lab-1.1-introduction-to-statistical-simulation",
    "href": "samp-dist.html#lab-1.1-introduction-to-statistical-simulation",
    "title": "1  Sampling Distributions",
    "section": "",
    "text": "Starting a Simulation\nTo begin a simulation for a sampling distribution of a sample statistic, we need to choose:\n\na population model for the simulation. Let’s think about \\(Y_i\\) as a random variable for the amount of time Mipha spends at the office in a week (in hours) as our context. Then, let’s start by assuming that each \\(Y_i\\) follows the following model: Normal(\\(\\mu\\) = 10, \\(\\sigma^2\\) = 4). Additionally, \\(Y_i\\)’s from different weeks are assumed to be independent.\na sample size for the simulation. Here, Mipha wants to consider the amount of time she spends at the office in 5 randomly selected weeks of the year. So, let’s start with \\(n\\) = 5.\na calculation for the sample statistic that we are constructing the sampling distribution of. Here, Mipha wants to examine what the sample mean amount of time she spends at the office from 5 randomly selected weeks looks like. So, let’s start by using the sample mean, \\(\\bar{y}\\).\n\nBefore we simulate anything, let’s use results from MATH/STAT 325 to report the theoretical distribution of the sample mean in the space below. Then, use this result to find the probability that the average amount of time Mipha spends at the office in 5 weeks is less than or equal to 9.5 hours per week and find the probability taht the average amount of time Mipha spends at the office in 5 weeks is more than 11 hours per week.\nGenerating a Single Sample Statistic\nCarefully look through this code and output to understand the process of generating a single sample from a population and computing a statistic.\nIn the code below, we simulate five observations from a normal population with mean 10 and standard deviation 2. Note that, when you run the code, you should get a different set of 5 numbers than the ones printed below: it is a random sample, after all!\n\nn &lt;- 5       # sample size\nmu &lt;- 10     # population mean\nsigma &lt;- 2   # population standard deviation\n\n# generate a random sample of n observations from a normal population\nsingle_sample &lt;- rnorm(n, mu, sigma) |&gt; round(2)\n# look at the sample\nsingle_sample \n#&gt; [1] 10.33 12.39  8.78  9.49  7.90\n\nNext, we compute the sample mean from this sample: this is our sample statistic we are interested in.\n\n# compute the sample mean\nsample_mean &lt;- mean(single_sample)\n# look at the sample mean\nsample_mean     \n#&gt; [1] 9.778\n\nAgain, your sample mean should be different!\nFinally, we can make a plot of our single sample, along with where the sample mean lies.\n\n# generate a range of values that span the population\nplot_df &lt;- tibble(xvals = seq(mu - 4 * sigma, mu + 4 * sigma, length.out = 500)) |&gt;\n  mutate(xvals_density = dnorm(xvals, mu, sigma))\n\n## plot the population model density curve\nggplot(data = plot_df, aes(x = xvals, y = xvals_density)) +\n  geom_line() +\n  theme_minimal() +\n  ## add the sample points from your sample\n  geom_jitter(data = tibble(single_sample), aes(x = single_sample, y = 0),\n              width = 0, height = 0.005) +\n  ## add a line for the sample mean\n  geom_vline(xintercept = sample_mean, colour = \"red\") +\n  labs(x = \"y\", y = \"density\",\n       title = \"Normal with Mu = 10 and sigma = 2\")\n\n\n\n\n\n\n\nConstructing the Sampling Distribution\nTo simulate the sampling distribution of the sample mean from a normal population with \\(\\mu\\) = 10 and \\(\\sigma\\) = 2 for a sample size of 5, we need to repeat the above steps many, many, many times. We can do so by\n\nWriting a function that computes the sample mean and then\nMapping through that function a large number of times and then\nPlotting the large number of sample means to examine the characteristics of the resulting distribution.\n\nFirst, let’s write the function that will compute the sample mean with a given sample size from a normal population model with a given mean and standard deviation.\n\nn &lt;- 5            # sample size\nmu &lt;- 10          # population mean\nsigma &lt;- 2        # population standard deviation\n\ngenerate_normal_mean &lt;- function(mu, sigma, n) {\n  \n  single_sample &lt;- rnorm(n, mu, sigma)\n  sample_mean &lt;- mean(single_sample)\n  \n  return(sample_mean)\n}\n\n## test function once:\ngenerate_normal_mean(mu = mu, sigma = sigma, n = n)\n#&gt; [1] 9.350331\n\nNext, to generate 5000 sample means, we map through the function:\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_normal_mean function\n## nsim times\nmeans &lt;- map_dbl(1:nsim, \\(i) generate_normal_mean(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmeans_df &lt;- tibble(means)\nmeans_df\n#&gt; # A tibble: 5,000 × 1\n#&gt;   means\n#&gt;   &lt;dbl&gt;\n#&gt; 1 10.1 \n#&gt; 2  8.72\n#&gt; 3 10.5 \n#&gt; 4  8.72\n#&gt; 5 10.0 \n#&gt; 6  9.50\n#&gt; # ℹ 4,994 more rows\n\nFinally, we plot the 5000 sample means to see what our sampling distribution of the sample mean (for a sample size of 5) looks like.\n\nggplot(data = means_df, aes(x = means)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Means\",\n       title = paste(\"Sampling Distribution of the \\nSample Mean when n =\", n))\n\n\n\n\n\n\n\nWe can also obtain some summary statistics of the sampling distribution of the sample mean when \\(n\\) = 5:\n\nmeans_df |&gt;\n  summarise(mean_samp_dist = mean(means),\n            var_samp_dist = var(means),\n            sd_samp_dist = sd(means))\n#&gt; # A tibble: 1 × 3\n#&gt;   mean_samp_dist var_samp_dist sd_samp_dist\n#&gt;            &lt;dbl&gt;         &lt;dbl&gt;        &lt;dbl&gt;\n#&gt; 1           10.0         0.794        0.891\n\nAnd, we can even obtain estimates of the probability that we observe a sample mean larger than 11 by calculating the proportion of our observed sample means that are larger than 11. We can use a similar strategy to estimate the probability that we observe a sample mean less than or equal to 9.5.\n\n# What is the probability that we observe a sample mean larger than 11?\nmeans_df |&gt;\n  mutate(more_than_11 = if_else(means &gt; 11,\n                                true = 1, false = 0)) |&gt;\n  summarise(prob_more_than_11 = mean(more_than_11))\n#&gt; # A tibble: 1 × 1\n#&gt;   prob_more_than_11\n#&gt;               &lt;dbl&gt;\n#&gt; 1             0.127\n\n# What is the probability that we observe a sample mean less than or equal to 9.5?\nmeans_df |&gt;\n  mutate(less_9.5 = if_else(means &lt;= 9.5,\n                            true = 1, false = 0)) |&gt;\n  summarise(prob_less_9.5 = mean(less_9.5))\n#&gt; # A tibble: 1 × 1\n#&gt;   prob_less_9.5\n#&gt;           &lt;dbl&gt;\n#&gt; 1         0.291\n\nExercise. Repeat the construction of the sampling distribution of the sample mean several times. How do the results change (or not)?\nExercise. Use the result from STAT 325 to report the theoretical distribution of the sample mean. Use this result to find \\(P(\\bar{Y}\\leq 9.5)\\) and \\(P(\\bar{Y}&gt;11)\\) analytically.\nExercise. What can we conclude about the sampling distribution of \\(\\bar{Y}\\) when taking samples of \\(n = 5\\) from this population? How do the simulation results compare to the result from STAT 325? Use the plot below in your answer to this question.\n\ntheoretical_df &lt;- tibble(xvals = seq(mu - 4 * sigma / sqrt(n),\n                                     mu + 4 * sigma / sqrt(n),\n                                     length.out = 500)) |&gt;\n  mutate(xvals_density = dnorm(xvals, mu, sigma / sqrt(n)))\n\nggplot(data = means_df, aes(x = means)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20,\n                 aes(y = after_stat(density))) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Means\",\n       title = paste(\"Sampling Distribution of the \\nSample Mean when n =\", n)) +\n  geom_line(data = theoretical_df, aes(x = xvals, y = xvals_density))\n\n\n\n\n\n\n\nExercise. Increase the sample size to 50 (so that Mipha is now considering the sampling distribution of the mean amount of time she spends at the office in 50 weeks) and then reconstruct the sampling distribution of the sample mean for \\(n = 50\\). How do the results (mean, standard deviation, and probabilities) change? Do the changes make sense and do they match the theoretical result from Stat 325?\nExercise. We mentioned that one assumption in our simulation is that each random variable is \\(iid\\): so, we assume that the amount time Mipha spends at the office in one week is independent of the amount of time she spends at the office in other weeks. Come up with a context for which the independence assumption might be violated in this setting.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling Distributions</span>"
    ]
  },
  {
    "objectID": "samp-dist.html#lab-1.2-samp.-dist.-with-a-non-normal-population",
    "href": "samp-dist.html#lab-1.2-samp.-dist.-with-a-non-normal-population",
    "title": "1  Sampling Distributions",
    "section": "Lab 1.2: Samp. Dist. with a Non-Normal Population",
    "text": "Lab 1.2: Samp. Dist. with a Non-Normal Population\nNow suppose that we can model the amount of time that Mipha walks in a day as an \\(Y_i \\sim\\) Exponential(\\(\\lambda\\) = 0.5) and that each \\(Y_i\\) is independent of other \\(Y_i\\). So, we have an Exponential(\\(\\lambda\\) = 0.5) population. Using a sample size of \\(n = 5\\) days, continue calculating the sample mean, \\(\\bar{y}\\). Before beginning, you should make sure to load in the tidyverse library again so that we can make some plots:\n\nlibrary(tidyverse)\n\nThe code below modifies the code from the previous section on a normal population model to reflect the updated exponential population model. Copy the code and run it in your own R session to obtain the graph of the exponential population model with a random sample of \\(n = 5\\) observations.\n\nn &lt;- 5       # sample size\nlambda &lt;- 0.5\nmu &lt;- 1 / lambda   # population mean\nsigma &lt;- sqrt(1 / lambda ^ 2)  # population standard deviation\n\n# generate a random sample of n observations from a normal population\nsingle_sample &lt;- rexp(n, lambda) |&gt; round(2)\n# look at the sample\nsingle_sample \n\n# compute the sample mean\nsample_mean &lt;- mean(single_sample)\n# look at the sample mean\nsample_mean \n\n# generate a range of values that span the population\nplot_df &lt;- tibble(xvals = seq(0, mu + 4 * sigma, length.out = 500)) |&gt;\n  mutate(xvals_density = dexp(xvals, lambda))\n\n## plot the population model density curve\nggplot(data = plot_df, aes(x = xvals, y = xvals_density)) +\n  geom_line() +\n  theme_minimal() +\n  ## add the sample points from your sample\n  geom_jitter(data = tibble(single_sample), aes(x = single_sample, y = 0),\n              width = 0, height = 0.005) +\n  ## add a line for the sample mean\n  geom_vline(xintercept = sample_mean, colour = \"red\") +\n  labs(x = \"y\", y = \"density\",\n       title = \"Exponential with Lambda = 0.5\")\n\nNow that we have an idea of what the population model looks like and we can generate a single sample from this model (along with the sample mean), we can repeat the generation of the sample mean thousands of times to construct the sampling distribution of the sample mean when \\(n = 5\\) for the exponential model.\n\nn &lt;- 5       # sample size\nlambda &lt;- 0.5\nmu &lt;- 1 / lambda   # population mean\nsigma &lt;- sqrt(1 / lambda ^ 2)  # population standard deviation\n\ngenerate_exp_mean &lt;- function(lambda, n) {\n  \n  single_sample &lt;- rexp(n, lambda)\n  sample_mean &lt;- mean(single_sample)\n  \n  return(sample_mean)\n}\n\n## test function once:\ngenerate_exp_mean(lambda = lambda, n = n)\n#&gt; [1] 1.304224\n\nnsim &lt;- 5000      # number of simulations\n\nmeans &lt;- map_dbl(1:nsim, \\(i) generate_exp_mean(lambda = lambda, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmeans_df &lt;- tibble(means)\nmeans_df\n#&gt; # A tibble: 5,000 × 1\n#&gt;   means\n#&gt;   &lt;dbl&gt;\n#&gt; 1  2.80\n#&gt; 2  1.26\n#&gt; 3  2.98\n#&gt; 4  2.08\n#&gt; 5  2.18\n#&gt; 6  3.39\n#&gt; # ℹ 4,994 more rows\n\nggplot(data = means_df, aes(x = means)) +\n  geom_histogram(colour = \"darkolivegreen4\", fill = \"darkolivegreen1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Means\",\n       title = paste(\"Sampling Distribution of the \\nSample Mean when n =\", n))\n\n\n\n\n\n\n\nExercise. In the code that generated the graph for the population model of the exponential distribution, along with the single sample and its mean, I modified the code from the normal distribution population model to examine a single sample from the known population, but for the Exponential population. What are some changes I made and why?\nExercise. Now look at the sampling distribution of the sample mean when \\(n = 5\\) for the exponential population model. Summarise what you notice about the sampling distribution of \\(\\bar{Y}\\) when taking a sample of size \\(n = 5\\) from an Exponential(\\(\\lambda\\) = 0.5) population.\nExercise. You should find that \\(\\text{E}(Y_i)\\) and \\(\\text{E}(\\bar{Y})\\) are equal to the same value. Using the context of this example (thinking about \\(Y_i\\) as a random variable for Mipha’s walking time in a day, in hours), explain what the difference between \\(\\text{E}(Y_i)\\) and \\(\\text{E}(\\bar{Y})\\) is, conceptually.\nExercise. You should find that \\(\\text{Var}(Y_i)\\) and \\(\\text{Var}(\\bar{Y})\\) are different. Using the context of this example (thinking about \\(Y_i\\) as a random variable for Mipha’s walking time in a day, in hours), explain why \\(\\text{Var}(Y_i)\\) is larger than \\(\\text{Var}(\\bar{Y})\\), conceptually.\nExercise. Increase the sample size to \\(n = 50\\). What do you notice about the sampling distribution of \\(\\bar{Y}\\) now? Why has the shape of the sampling distribution changed?\nExercise. In general, what are some other ways you could summarise a sample of data? (i.e., other calculations you could do?)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling Distributions</span>"
    ]
  },
  {
    "objectID": "samp-dist.html#lab-1.3-samp.-dist.-of-the-sample-minimum",
    "href": "samp-dist.html#lab-1.3-samp.-dist.-of-the-sample-minimum",
    "title": "1  Sampling Distributions",
    "section": "Lab 1.3: Samp. Dist. of the Sample Minimum",
    "text": "Lab 1.3: Samp. Dist. of the Sample Minimum\nAgain, load in the tidyverse library so that we can make some plots!\n\nlibrary(tidyverse)\n\nLet’s return to our original context, thinking about Mipha’s weekly office time that can be modeled as: Normal(\\(\\mu\\) = 10, \\(\\sigma^2\\) = 4). But, now the young Mipha is interested in a different statistic: the sample minimum time she is in the office in 5 weeks. Examine the code that you ran in an earlier lab below.\n\nn &lt;- 5       # sample size\nmu &lt;- 10     # population mean\nsigma &lt;- 2   # population standard deviation\n\n# generate a random sample of n observations from a normal population\nsingle_sample &lt;- rnorm(n, mu, sigma) |&gt; round(2)\n# look at the sample\nsingle_sample \n\n# compute the sample mean\nsample_mean &lt;- mean(single_sample)\n# look at the sample mean\nsample_mean   \n\n# generate a range of values that span the population\nplot_df &lt;- tibble(xvals = seq(mu - 4 * sigma, mu + 4 * sigma, length.out = 500)) |&gt;\n  mutate(xvals_density = dnorm(xvals, mu, sigma))\n\n## plot the population model density curve\nggplot(data = plot_df, aes(x = xvals, y = xvals_density)) +\n  geom_line() +\n  theme_minimal() +\n  ## add the sample points from your sample\n  geom_jitter(data = tibble(single_sample), aes(x = single_sample, y = 0),\n              width = 0, height = 0.005) +\n  ## add a line for the sample mean\n  geom_vline(xintercept = sample_mean, colour = \"red\") +\n  labs(x = \"y\", y = \"density\",\n       title = \"Normal with Mu = 10 and sigma = 2\")\n\nExercise. Modify the code so that, instead of calculating the sample mean as the sample statistic, you calculate the sample minimum as the sample statistic. Then, re-run the code so that you better understand what the sampling distribution of the sample minimum might look like.\nExercise. Predict what might happen next! That is, based on what you’ve seen by re-running the code above, where do you expect the center of the sampling distribution of the sample minimum to be relative to 10? Do you expect the sampling distribution of the sample minimum to overlap with the value 10 at all (if \\(n = 5\\)).\nExercise. Modify the code below so that you generate the sampling distribution of the sample minimum instead of the sample mean.\n\nn &lt;- 5            # sample size\nmu &lt;- 10          # population mean\nsigma &lt;- 2        # population standard deviation\n\ngenerate_samp_mean &lt;- function(mu, sigma, n) {\n  \n  single_sample &lt;- rnorm(n, mu, sigma)\n  sample_mean &lt;- mean(single_sample)\n  \n  return(sample_mean)\n}\n\n## test function once:\ngenerate_samp_mean(mu = mu, sigma = sigma, n = n)\n\nnsim &lt;- 5000      # number of simulations\n\n## code to map through the function. \n## the \\(i) syntax says to just repeat the generate_samp_mean function\n## nsim times\nmeans &lt;- map_dbl(1:nsim, \\(i) generate_samp_mean(mu = mu, sigma = sigma, n = n))\n\n## print some of the 5000 means\n## each number represents the sample mean from __one__ sample.\nmeans_df &lt;- tibble(means)\nmeans_df\n\nggplot(data = means_df, aes(x = means)) +\n  geom_histogram(colour = \"deeppink4\", fill = \"deeppink1\", bins = 20) +\n  theme_minimal() +\n  labs(x = \"Observed Sample Means\",\n       title = paste(\"Sampling Distribution of the \\nSample Mean when n =\", n))\n\nmeans_df |&gt;\n  summarise(mean_samp_dist = mean(means),\n            var_samp_dist = var(means),\n            sd_samp_dist = sd(means))\n\nmeans_df |&gt;\n  mutate(more_than_11 = if_else(means &gt; 11,\n                                true = 1, false = 0)) |&gt;\n  summarise(prob_more_than_11 = mean(more_than_11))\n\nmeans_df |&gt;\n  mutate(less_9.5 = if_else(means &lt;= 9.5,\n                            true = 1, false = 0)) |&gt;\n  summarise(prob_less_9.5 = mean(less_9.5))\n\nExercise. Summarise what you notice about the sampling distribution. How does it compare to the sampling distribution of the sample mean? Does that make sense? Why or why not?\nExercise. Report the probability that the sample minimum is less than or equal to 9.5. How does it compare to the probability that the sample mean is less than or equal to 9.5? Does that make sense? Why or why not?\nExercise. Increase the sample size to 50. Summarize how the sampling distribution of the sample minimum when \\(n = 50\\) differs from when \\(n = 5\\).\nExercise. Note that the sampling distribution does not appear to be normally distributed. Do you think that if we upped the sample size to a larger value (say \\(n = 1000\\)), that the sampling distribution will be normally distributed? Why or why not?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling Distributions</span>"
    ]
  },
  {
    "objectID": "samp-dist.html#mini-project-1-sampling-distribution-of-the-sample-minimum-and-maximum",
    "href": "samp-dist.html#mini-project-1-sampling-distribution-of-the-sample-minimum-and-maximum",
    "title": "1  Sampling Distributions",
    "section": "Mini Project 1: Sampling Distribution of the Sample Minimum and Maximum",
    "text": "Mini Project 1: Sampling Distribution of the Sample Minimum and Maximum\nAI Usage: You may not use generative AI for this project in any way.\nCollaboration: For this project, you may work with a self-contained group of 3. Keep in mind that you may not work with the same person on more than one mini-project (so, if you worked with a student on the first mini-project as a partner or in a small group, you may not work with that person on this project). Finally, if working with a partner or in a group of 3, you may submit the same code and the same table of results, but your write-up (both the short summary of your methods and your findings summary) must be written individually.\nStatement of Integrity: At the top of your submission, copy and paste the following statement and type your name, certifying that you have followed all AI and collaboration rules for this mini-project.\n“I have followed all rules for collaboration for this project, and I have not used generative AI on this project.”\n\nOn our second day of class, we conducted a simulation to investigate the sampling distribution of the sample minimum (\\(Y_{min}\\)) when taking samples of \\(n = 5\\) observations from a Normal(\\(\\mu = 10, \\sigma^2 = 4\\)) population. For your recap of that day, you investigated the sampling distribution of the sample maximum (\\(Y_{max}\\)) from the same population (using the same sample size).\nMany of you noticed that, in this situation, SE(\\(Y_{min}\\)) \\(\\approx\\) SE(\\(Y_{max}\\)), and many of you provided great explanations of why you thought that was true. The purpose of this mini-project assignment is for you to investigate this phenomenon to see if it is a result that holds more generally.\nInstructions: Use the class code as a guide to carry out simulations of the sampling distributions of the sample minimum (\\(Y_{min}\\)) and the sample maximum (\\(Y_{max}\\)) when taking samples of size \\(n = 5\\) from different populations (specified below). Fill in the summary table in this document and use it answer the questions that follow.\nSubmission: Upload your typed up solutions to the questions that appear below, graphs (population graphs, histograms of your simulated distributions of the sample minimum, and histograms of your simulated distributions of the sample maximum), and tables showing your results, and your Quarto file to Canvas.\nBelow are some things that you can use to help make your graphs and table in Quarto, should you desire to use that to render a document to submit.\n\nlibrary(tidyverse)\n## create population graphs\n\nnorm_df &lt;- tibble(x = seq(3, 17, length.out = 1000),\n                  dens = dnorm(x, mean = 10, sd = 2),\n                  pop = \"normal(10, 4)\")\nunif_df &lt;- tibble(x = seq(7, 13, length.out = 1000),\n                  dens = dunif(x, 7, 13),\n                  pop = \"uniform(7, 13)\")\nexp_df &lt;- tibble(x = seq(0, 10, length.out = 1000),\n                 dens = dexp(x, 0.5),\n                 pop = \"exp(0.5)\")\nbeta_df &lt;- tibble(x = seq(0, 1, length.out = 1000),\n                  dens = dbeta(x, 8, 2),\n                  pop = \"beta(8, 2)\")\n\npop_plot &lt;- bind_rows(norm_df, unif_df, exp_df, beta_df) |&gt;\n  mutate(pop = fct_relevel(pop, c(\"normal(10, 4)\", \"uniform(7, 13)\",\n                                  \"exp(0.5)\", \"beta(8, 2)\")))\n\nggplot(data = pop_plot, aes(x = x, y = dens)) +\n  geom_line() +\n  theme_minimal() +\n  facet_wrap(~ pop, nrow = 1, scales = \"free\") +\n  labs(title = \"Population Distributions for Each Simulation Setting\")\n\n\n\n\n\n\n\nIf creating your report in Quarto, you can use a similar strategy as above to show your 4 histograms of the simulated distribution of the sample minimum and to again show your 4 histograms of the simulated distribution of the sample maximum.\nIn addition to your graphs, you should also complete the following table:\n\nTable of Results\n\n\n\n\n\n\n\n\n\n\\(\\text{N}(\\mu = 10, \\sigma^2 = 4)\\)\n\\(\\text{Unif}(\\theta_1 = 7, \\theta_2 = 13)\\)\n\\(\\text{Exp}(\\lambda = 0.5)\\)\n\\(\\text{Beta}(\\alpha = 8, \\beta = 2)\\)\n\n\n\n\\(\\text{E}(Y_{min})\\)\n\n\n\n\n\n\n\\(\\text{E}(Y_{max})\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\text{SE}(Y_{min})\\)\n\n\n\n\n\n\n\\(\\text{SE}(Y_{max})\\)\n\n\n\n\n\n\n\nBelow is the Quarto text used to generate the table above:\n|  |  $\\text{N}(\\mu = 10, \\sigma^2 = 4)$  | $\\text{Unif}(\\theta_1 = 7, \\theta_2 = 13)$ | $\\text{Exp}(\\lambda = 0.5)$ | $\\text{Beta}(\\alpha = 8, \\beta = 2)$ |\n|:----:|:-----------------:|:-------------:|:------------:|:------------:|\n| $\\text{E}(Y_{min})$    |       |        |       |              |\n| $\\text{E}(Y_{max})$    |       |        |       |              |\n|                        |       |        |       |              |\n| $\\text{SE}(Y_{min})$   |       |        |       |              |\n| $\\text{SE}(Y_{max})$   |       |        |       |              |\n: Table of Results {.striped .hover}\nFinally, in addition to your code, graphs, and table, you should answer the following questions:\n\nBriefly summarise how \\(\\text{SE}(Y_{min})\\) and \\(\\text{SE}(Y_{max})\\) compare for each of the above population models. Can you propose a general rule or result for how \\(\\text{SE}(Y_{min})\\) and \\(\\text{SE}(Y_{max})\\) compare for a given population?\nChoose either the third (Exponential) or fourth (Beta) population model from the table above. For that population model, find the pdf of \\(Y_{min}\\)⁡ and \\(Y_{max}\\), and, for each of those random variables, sketch the pdfs and use integration to calculate the expected value and standard error. What do you notice about how your answers compare to the simulated answers? Some code is given below to help you plot the pdfs in R:\n\n\nn &lt;- 5\n## CHANGE 0 and 3 to represent where you want your graph to start and end\n## on the x-axis\nx &lt;- seq(0, 3, length.out = 1000)\n## CHANGE to be the pdf you calculated. Note that, as of now, \n## this is not a proper density (it does not integrate to 1).\ndensity &lt;- n * exp(-(1/2) * x)\n\n\n## put into tibble and plot\nsamp_min_df &lt;- tibble(x, density)\nggplot(data = samp_min_df, aes(x = x, y = density)) +\n  geom_line() +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Sampling Distributions</span>"
    ]
  },
  {
    "objectID": "estimation.html",
    "href": "estimation.html",
    "title": "2  Estimation",
    "section": "",
    "text": "Lab 2.1: Maximum Likelihood Estimation\nIn this subsection, we make a few plots of various likelihoods we have encountered so far. Note that the likelihood plot will change for different data, and, if you would like, you can put in different data vectors to see how the likelihood changes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimation</span>"
    ]
  },
  {
    "objectID": "estimation.html#lab-2.1-maximum-likelihood-estimation",
    "href": "estimation.html#lab-2.1-maximum-likelihood-estimation",
    "title": "2  Estimation",
    "section": "",
    "text": "MLE Example: Binomial Likelihood\nThe code below examines the likelihood of \\(p\\) in a binomial setting with known \\(n\\). The peak shown in the plot gives the value of \\(p\\) that maximizes this likelihood.\n\nlibrary(tidyverse)\n\n## get binomial likelihood for each value of p\n## p is a vector of probabilities\n## n is a single value for the sample size\n## dat is a vector of data\n\nget_binom_lik &lt;- function(p, n, data_vec) {\n  \n  ## for each value of p, map through the dbinom function for\n  ## each data point (and multiply the results at the end to obtain\n  ## the likelihood)\n  binom_lik &lt;- map_dbl(p,\n                       ~ dbinom(x = data_vec, size = n, prob = .x) |&gt;\n                         prod() ## like the capital Pi in formula\n  )\n  \n  ## the function returns a vector of likelihoods for each\n  ## candidate p (and will be a vector of the same length as p)\n  return(binom_lik)\n}\n\n\np &lt;- seq(0, 1, by = 0.001)\nn &lt;- 20\ndat &lt;- c(5, 4, 2, 1, 0, 1, 2)\n\nbinom_liks &lt;- get_binom_lik(p = p, n = n, data_vec = dat)\n\nlik_df &lt;- tibble(p, binom_liks)\nggplot(data = lik_df, aes(x = p, y = binom_liks)) +\n  geom_line() +\n  labs(y = \"Likelihood\") +\n  theme_minimal()\n\nSecondly, let’s graph the likelihood and the log-likelihood to try and convince ourselves that maximizing the log-likelihood is an equivalent approach to maximizing the likelihood:\n\nget_binom_log_lik &lt;- function(p, n, data_vec) {\n  \n  ## for each value of p, map through the dbinom function for\n  ## each data point (and multiply the results at the end to obtain\n  ## the likelihood)\n  binom_log_lik &lt;- map_dbl(p,\n                       ~ dbinom(x = data_vec, size = n, prob = .x,\n                                log = TRUE) |&gt;\n                         sum() ## like the summation in formula\n  )\n  \n  ## the function returns a vector of likelihoods for each\n  ## candidate p (and will be a vector of the same length as p)\n  return(binom_log_lik)\n}\n\n\np &lt;- seq(0.01, 0.5, by = 0.001)\nn &lt;- 20\ndat &lt;- c(5, 4, 2, 1, 0, 1, 2)\n\nbinom_liks &lt;- get_binom_lik(p = p, n = n, data_vec = dat)\nbinom_log_liks &lt;- get_binom_log_lik(p = p, n = n, data_vec = dat)\n\nlik_df &lt;- tibble(p, binom_liks, binom_log_liks) |&gt;\n  pivot_longer(2:3, names_to = \"lik_type\", values_to = \"L\")\nggplot(data = lik_df, aes(x = p, y = L)) +\n  geom_line() +\n  facet_wrap(~ lik_type, scales = \"free_y\", nrow = 2) +\n  labs(y = \"Likelihood\") +\n  theme_minimal()\n\nExercise. Both the likelihood and the log likelihood plots given above are plots of the likelihood of \\(p\\) given our observed data \\(5, 4, 2, 1, 0, 1, 2\\). Suppose that, instead of the data given above, we actually observed the following data: \\(10, 9, 7, 6, 5, 6, 7\\). How do you think the likelihood and log-likelihood plots would change given this new data? Draw a sketch of a possible likelihood and log-likelihood given this new observed data over the current plot.\nExercise. Use your knowledge from calculus as well as the plots given to explain why we can find the MLE by taking the derivative of the likelihood and setting the resulting equation equal to 0.\nExercise. We mentioned in class that instead of taking the derivative of the likelihood, it’s easier to take the derivative of the log-likelihood. Explain why employing this strategy still yields the MLE using the plots above.\nMLE Example: Rayleigh Distribution\nIn class, we derived the MLE for the parameter \\(\\theta\\) in the probability model:\n\\[\nf(x \\vert \\theta) = \\frac{2x}{\\theta} e^{-\\frac{x^2}{\\theta}},\n\\]\nHere, we graph that likelihood for a sample of \\(n = 10\\) data points.\n\nthetas &lt;- seq(0, 30, length.out = 1000)  ## may need to adjust these limits\ndat &lt;- c(0.9, 1.5, 2, 4.2, 1.2, 5.2, 6.7, 2.1, 1.5, 2.3)\n\nget_theta_lik &lt;- function(theta, data_vec) {\n  ## since there is no \"dbinom\" equivalent for the unnamed probability model\n  ## we have to code f(x \\vert \\theta) \"by hand\":\n  theta_lik &lt;- map_dbl(theta,\n                       ~ ((2 * data_vec / .x) * exp(-data_vec^2 / .x)) |&gt;\n                         prod()\n  )\n  \n  return(theta_lik)\n}\n \ntheta_liks &lt;- get_theta_lik(theta = thetas, data_vec = dat)\n\nlik_df &lt;- tibble(thetas, theta_liks)\nggplot(data = lik_df, aes(x = thetas, y = theta_liks)) +\n  geom_line() +\n  labs(y = \"Likelihood\") +\n  theme_minimal()\n\nMLE Example: Poisson\nConsider the likelihood of various values of \\(\\lambda\\), where the random sample of data is from a Poisson probability model.\n\ndat &lt;- c(8, 0, 4, 9, 1)\nlambdas &lt;- seq(0, 10, length.out = 1000) ## may need to adjust these limits\n\n\nget_poisson_lik &lt;- function(lambda, data_vec) {\n  \n  poisson_lik &lt;- map_dbl(lambda,\n                         ~ dpois(x = data_vec, lambda = .x) |&gt;\n                           prod()\n  )\n  \n  return(poisson_lik)\n}\n\npoisson_liks &lt;- get_poisson_lik(lambda = lambdas, data_vec = dat)\nlik_df &lt;- tibble(lambdas, poisson_liks)\nggplot(data = lik_df, aes(x = lambdas, y = poisson_liks)) +\n  geom_line() +\n  labs(y = \"Likelihood\") +\n  theme_minimal()\n\n\n\n\n\n\n\nExercise. Many of the most common likelihood functions are unimodal with a single peak (so, there is a single MLE). Draw a sketch of a likelihood function such that using our strategy of finding the MLE (taking the derivative and setting equal to 0) would fail.\nExercise. Many of the most common likelihood functions are unimodal with a single peak (so, there is a single MLE). Draw another sketch of a likelihood function such that using our strategy of finding the MLE (taking the derivative and setting equal to 0) would fail.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimation</span>"
    ]
  },
  {
    "objectID": "estimation.html#lab-2.2-mles-in-practice",
    "href": "estimation.html#lab-2.2-mles-in-practice",
    "title": "2  Estimation",
    "section": "Lab 2.2 MLEs in Practice",
    "text": "Lab 2.2 MLEs in Practice\nMost of the estimators that you have seen in other STAT courses are MLEs, including the estimators for slope coefficients in linear regression models. While it is harder to derive these “by hand” due to the amount of algebra, let’s look at some code that computes the likelihood of the simple linear regression model: \\(Y_i = \\beta_0 + \\beta_1x_i + \\epsilon_i\\), where \\(\\epsilon_i \\sim N(0, \\sigma^2)\\) and are each independent.\nExercise. In simple linear regression, \\(\\beta_0\\), \\(\\beta_1\\) and \\(x_i\\) are all considered to be “constants” while \\(Y_i\\) and \\(\\epsilon_i\\) are considered to be random variables. Using rules of expectation and variance, find the expectation and variance of \\(Y_i\\). Additionally, what is the distribution of \\(Y_i\\) (we proved this back in Probability: see if you can remember!).\nExercise. Write out the likelihood for \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma\\) given our observed data \\(y_1, y_2, \\ldots y_n\\) and \\(x_1, x_2, \\ldots, x_n\\).\nExercise. If we were to find our estimators by hand, how many derivatives of the likelihood would we need to take?\nSuppose that we want to fit a linear regression model using the number of graduating majors from our department as the response variable and year as the predictor variable from 2002 through 2022. The data has been put into a tibble and has been plotted below:\n\nlibrary(tidyverse)\nyear &lt;- 2:22\nmcss_majors &lt;- c(15, 27, 30, 29, 45, 38, 35, 39, 49, 25, 40, 38, 53, 38, 52, 62, 37, 72, 65, 50, 55)\nmcss_df &lt;- tibble(year, mcss_majors)\nggplot(data = mcss_df, aes(x = year, y = mcss_majors)) +\n  geom_point() +\n  theme_minimal()\n\n\n\n\n\n\n\nThe following is some code that I modified from ChatGPT to compute the likelihood for values of \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma^2\\) and a given vector of a predictor variable x and a vector of a response variable y.\n\n# Function to compute the likelihood for simple linear regression\ncompute_likelihood &lt;- function(intercept, slope, sigma, x, y) {\n  # Number of observations\n  n &lt;- length(y)\n  \n  # Compute predicted values\n  y_pred &lt;- intercept + slope * x\n  \n  # Compute residuals\n  residuals &lt;- y - y_pred\n  \n  # Compute the likelihood\n  likelihood &lt;- (1 / (sqrt(2 * pi) * sigma)^n) * \n                exp(-sum(residuals^2) / (2 * sigma^2))\n  \n  return(likelihood)\n}\n\n# Compute likelihood once\ncompute_likelihood(intercept = 20, slope = 2, sigma = 7,\n                                 x = mcss_df |&gt; pull(year),\n                                 y = mcss_df |&gt; pull(mcss_majors))\n\n[1] 1.134363e-34\n\n\nAnd then this is my own code (ChatGPT failed or I misused it somehow) to loop through the compute_likelihood() function to compute the likelihood for a grid of possible values for \\(\\beta_0\\), \\(\\beta_1\\), and \\(\\sigma\\).\n\n## set up grid of possible values\nintercept &lt;- seq(20, 23, length.out = 50)\nslope &lt;- seq(1.6, 1.9, length.out = 50)\nsigma &lt;- seq(8.5, 9.5, length.out = 50)\n\ngrid &lt;- expand_grid(intercept, slope, sigma)\n\nliks &lt;- pmap_dbl(grid, ~ compute_likelihood(..1, ..2, ..3,\n                                            x = mcss_df |&gt; pull(year),\n                                            y = mcss_df |&gt; pull(mcss_majors)))\n\nlikelihood_df &lt;- grid |&gt; mutate(likelihood = liks)\nlikelihood_df\n\n# A tibble: 125,000 × 4\n   intercept slope sigma likelihood\n       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n 1        20   1.6  8.5    2.03e-34\n 2        20   1.6  8.52   2.06e-34\n 3        20   1.6  8.54   2.08e-34\n 4        20   1.6  8.56   2.11e-34\n 5        20   1.6  8.58   2.14e-34\n 6        20   1.6  8.60   2.16e-34\n 7        20   1.6  8.62   2.19e-34\n 8        20   1.6  8.64   2.21e-34\n 9        20   1.6  8.66   2.24e-34\n10        20   1.6  8.68   2.26e-34\n# ℹ 124,990 more rows\n\n\n\nggplot(data = likelihood_df, aes(x = intercept, y = slope)) +\n  geom_tile(aes(fill = likelihood)) +\n  scale_fill_viridis_c() +\n  theme_minimal()\n\n\n\n\n\n\n\nExercise. Write a short summary of what the above code is doing. What is represented in a single row of likelihood_df?\nExercise. Based on the plot of the likelihood of the various slope and intercept combinations, what does it look like the approximate maximum likelihood estimates are?\nExercise. Run the following code to find the row in the grid that has the maximum likelihood.\n\nlikelihood_df |&gt; filter(likelihood == max(likelihood))\n\n# A tibble: 1 × 4\n  intercept slope sigma likelihood\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1      21.6  1.75  8.93   1.25e-33\n\n\nBased on our grid search, what are the maximum likelihood estimates for \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma\\) in this example?\nExercise. Now, fit the linear regression model using lm():\n\nlm(mcss_majors ~ year, data = mcss_df) |&gt;\n  summary()\n\n\nCall:\nlm(formula = mcss_majors ~ year, data = mcss_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-16.060  -6.319   0.161   6.933  17.192 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  21.5948     4.5443   4.752 0.000139 ***\nyear          1.7481     0.3381   5.170 5.44e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.382 on 19 degrees of freedom\nMultiple R-squared:  0.5845,    Adjusted R-squared:  0.5627 \nF-statistic: 26.73 on 1 and 19 DF,  p-value: 5.441e-05\n\n\nLocate the estimates for \\(\\beta_0\\), \\(\\beta_1\\) and \\(\\sigma\\) in the output. Do all of these estimates match what we found with our grid search to find the estimates that give the maximum likelihood?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimation</span>"
    ]
  },
  {
    "objectID": "estimation.html#lab-2.3-mse-consistency",
    "href": "estimation.html#lab-2.3-mse-consistency",
    "title": "2  Estimation",
    "section": "Lab 2.3: MSE Consistency",
    "text": "Lab 2.3: MSE Consistency\nIn this subsection, we illustrate an example visualizing some of the mean square error results we derived in class as well as a couple of consistent estimators.\nMSE Graph\nHere, we again the example where \\(X_1, X_2, \\ldots, X_n\\) are independent and identically distributed random variables with a \\(\\text{Unif}(0, \\theta)\\) distribution. We now have three estimators: \\(\\hat{\\theta}_{MOM}\\), \\(\\hat{\\theta}_{MLE}\\), and \\(\\hat{\\theta}^*\\). We have already derived both the MLE, the MOM estimator, and adjusted the MLE to make a new, unbiased estimator based on the MLE. We also calculated the MSE of each of our three candidate estimators.\nNow, we make a plot of the MSE for \\(1 \\leq n \\leq 20\\).\n\n\n\nlibrary(tidyverse)\nn &lt;- 1:20\ntheta &lt;- 1\nmse_mom &lt;- (1 / (3 * n)) * theta^2\nmse_mle &lt;- (2 / ((n + 1) * (n + 2))) * theta^2\nmse_mle_unb &lt;- (1 / ((n * (n + 2)))) * theta^2\n\nmse_plot &lt;- tibble::tibble(n, mse_mom, mse_mle, mse_mle_unb) |&gt;\n  pivot_longer(2:4, names_to = \"estimator\", values_to = \"mse\")\nggplot(data = mse_plot, aes(x = n, y = mse)) +\n  geom_line(aes(colour = estimator)) +\n  theme_minimal() +\n  scale_colour_viridis_d()\n\n\n\n\n\n\n\nExercise. How do these results match your theoretical calculations? Which of the three estimators seems most preferable?\nExercise. Consider two generic estimators for a parameter \\(\\theta\\), and denote these estimators \\(\\hat{\\theta}_1\\) and \\(\\hat{\\theta}_2\\). Draw a plot similar to the plot given above (\\(n\\) on x-axis, MSE on y-axis) that shows that \\(\\hat{\\theta}_1\\) is preferable at some sample sizes but \\(\\hat{\\theta}_2\\) is preferable for other sample sizes.\n\nBinomial Example Consistency\n\nlibrary(tidyverse)\np &lt;- 1 / 4 ## specify probability of success for the simulation\n\nnsim &lt;- 1000 ## specify range of possible ns (how long we will run the simulation)\n\ncompute_binom_estimator &lt;- function(p, nsim) {\n  \n  ## draw nsim different of 0's and 1's\n  bernoulli_draws &lt;- rbinom(n = nsim, size = 1, prob = p)\n\n  ## compute the estimator of p\n  ## nsim different times (once using a sample of 1 bernoulli, then\n  ## using a sample of 2 bernoullis, ....,\n  ##  then using a sample of nsim bernoullis)\n  \n  binom_mle &lt;- map_dbl(1:nsim, ~ sum(bernoulli_draws[1:.x]) / .x)\n\n\n  ## put all three results into a data frame, along with n\n  output_df &lt;- tibble(n = 1:nsim, binom_mle)\n  \n  return(output_df)\n}\n\nplot_df &lt;- compute_binom_estimator(p = p, nsim = nsim)\n\nggplot(data = plot_df, aes(x = n,\n                             y = binom_mle)) +\n  geom_line() +\n  geom_hline(yintercept = p, linetype = 2) +\n  theme_minimal() +\n  labs(x = \"n (Sample Size)\",\n       caption = \"Dotted Line Shows True Value of p\")\n\n\n\n\n\n\n\nExercise. On the plot above, sketch in an estimator that does not exhibit evidence of consistency because the estimator does not seem to be asymptotically unbiased.\nExercise. In the provided lab code, change nsim to be equal to 50. Does the MLE look like it converges to the true value of \\(p\\)? Explain why the resulting plot is not enough to confirm whether or not the estimator is consistent for \\(p\\).\n\nUniform Example Consistency\n\ntheta &lt;- 10  ## specify an upper bound for our uniform model\n## recall that the lower bound is known and is equal to 0\n\nnsim &lt;- 1000 ## specify range of possible sample sizes (how long we will run the simulation)\n\n## compute each estimator of theta using adjusted MLE, MLE, and MOM\ncompute_unif_estimators &lt;- function(theta, nsim) {\n  \n  unif_draws &lt;- runif(n = nsim, min = 0, max = theta)\n\n  ## compute the method of moment estimator \n  ## nsim different times (once using a sample of size 1, then\n  ## using a sample of size 2, ...., then using a sample of size nsim)\n  unif_mom &lt;- map_dbl(1:nsim, ~ 2 * mean(unif_draws[1:.x]))\n  \n  ## same type of computation for MLE\n  unif_mle &lt;- map_dbl(1:nsim, ~ max(unif_draws[1:.x]))\n  \n  ## same type of computation for adjusted MLE\n  unif_mle_adj &lt;- map_dbl(1:nsim,\n                          ~ ((.x + 1) / .x) * max(unif_draws[1:.x]))\n\n  ## put all three results into a data frame, along with n\n  output_df &lt;- tibble(n = 1:nsim, \n         unif_mom, unif_mle, unif_mle_adj)\n  \n  return(output_df)\n}\n\nplot_df &lt;- compute_unif_estimators(theta = theta, nsim = nsim)\n\n\n## do some DATA/STAT 234-type Work to make the plot\n\nplot_long &lt;- plot_df |&gt; pivot_longer(cols = starts_with(\"unif\"),\n                                     names_to = \"Estimator\",\n                                     values_to = \"theta_estimate\")\nggplot(data = plot_long, aes(x = n,\n                             y = theta_estimate,\n                             colour = Estimator)) +\n  geom_line() +\n  geom_hline(yintercept = theta, linetype = 2) +\n  scale_colour_viridis_d(end = 0.9) +\n  theme_minimal() +\n  labs(x = \"n (Sample Size)\",\n       caption = \"Dotted Line Shows True Value of Theta\")\n\n\n\n\n\n\n\nExercise. On the plot above, sketch in an estimator that does not exhibit evidence of consistency because the estimator’s asymptotic variance does not seem to go to 0.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimation</span>"
    ]
  },
  {
    "objectID": "estimation.html#mini-project-2-a-meaningful-story",
    "href": "estimation.html#mini-project-2-a-meaningful-story",
    "title": "2  Estimation",
    "section": "Mini Project 2: A Meaningful Story",
    "text": "Mini Project 2: A Meaningful Story\nAI Usage: You may not use generative AI for this project in any way.\nCollaboration: For this project, you may not work with other people in the class. Your story must be your own.\nStatement of Integrity: Your submission should be typed. At the top of your submission, copy and paste the following statement and type your name, certifying that you have followed all AI and collaboration rules for this mini-project.\n“All work presented is my own, and I have followed all rules for collaboration. I have not used generative AI on this project.”\nFor this mini-project, you will write a “meaningful story.” A “meaningful story” is one continuous piece of writing / creative work that uses key words from a list and in which the sentences “make sense and hang together.” That is, the ideas in the story must illustrate that you understand key concepts from Stat 326 in a way that allows you to write “meaningfully” about them. You may not simply write ten sequential sentences that merely define the terms; the sentences must demonstrate relationships between the terms. It is your job to use the terms in a way that demonstrates that you understand the statistical concepts involved and why we care about these terms in the big picture of statistical theory.\nIn addition, you need to frame your writing within a real-life or imaginary context or scenario. Be creative!! Write about sports or music or manufacturing cell phones or skiing trips or the zombie apocalypse. Meaningful stories could even be literary works, such as play scripts, stories, song lyrics, poetry, etc. Use your imagination when constructing your “story” and conveying the material (content MUST be appropriate).\nEstimation Prompt: Each of these terms must be incorporated into your meaningful story. Estimator, Parameter, Estimate (as a noun), Random Variable, Random Sample, Bias, Variance, Consistent, Likelihood.\nAlso: in your “meaningful story,” you must refer to at least one of our common probability distributions by name.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimation</span>"
    ]
  },
  {
    "objectID": "conf-int.html",
    "href": "conf-int.html",
    "title": "3  Confidence Intervals",
    "section": "",
    "text": "Lab 3.1: A Tiny, Tiny, Tiny Glimpse into DATA/STAT 234\nThis first subsection is a little disconnected from what we have discussing in class, but the purpose of having this section in this class is to give you some practice constructing basic graphs and obtaining basic summary statistics with DATA/STAT 234-style code. The reason we have this subsection here is so that you can make these graphs to investigate various assumptions of the confidence intervals and hypothesis tests we will discuss in the latter part of the semester.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "conf-int.html#lab-3.1-a-tiny-tiny-tiny-glimpse-into-datastat-234",
    "href": "conf-int.html#lab-3.1-a-tiny-tiny-tiny-glimpse-into-datastat-234",
    "title": "3  Confidence Intervals",
    "section": "",
    "text": "Plotting\nIf we are not using the Central Limit Theorem to obtain the (approximate) sampling distribution of the sample mean, we must plot the data to determine if it could have plausibly come from a Normal population (looking for rough symmetric and absence of outliers). While we have lots of options here (including histograms and normal quantile plots), I like a boxplot, especially in two sample situations.\nFor this illustration, we’ll use the Beerwings dataset from the textbook to show how to make plots of a single quantitative variable.\n\nlibrary(tidyverse)\nlibrary(resampledata)\n\n## convert Beerwings data frame to a tibble for nicer printing\nbeerwings_df &lt;- Beerwings |&gt; as_tibble() \nbeerwings_df\n\nLet’s first consider the data as a single sample and explore the distributions of both Beer consumption and Hotwing consumption (only the beer consumption plots are printed below):\n\nggplot(data = beerwings_df, aes(x = Beer)) +\n  geom_histogram(bins = 8, colour = \"black\", fill = \"mediumseagreen\") +\n  theme_minimal()\n\n\n\n\n\n\nggplot(data = beerwings_df, aes(x = Beer)) +\n  geom_boxplot(fill = \"mediumseagreen\") +\n  theme_minimal()\n\n\n\n\n\n\nggplot(data = beerwings_df, aes(sample = Beer)) +\n  stat_qq() +\n  stat_qq_line() +\n  theme_minimal()\n\n\n\n\n\n\n\n\nggplot(data = beerwings_df, aes(x = Hotwings)) +\n  geom_histogram(bins = 8, colour = \"black\", fill = \"mediumseagreen\") +\n  theme_minimal()\nggplot(data = beerwings_df, aes(x = Hotwings)) +\n  geom_boxplot(fill = \"mediumseagreen\") +\n  theme_minimal()\nggplot(data = beerwings_df, aes(sample = Hotwings)) +\n  stat_qq() +\n  stat_qq_line() +\n  theme_minimal()\n\nNow, let’s compare the distribution of hotwings for each sex in the data set with a set of side-by-side boxplots:\n\nggplot(data = beerwings_df, aes(x = Gender, y = Hotwings)) +\n  geom_boxplot(fill = \"steelblue\") +\n  theme_minimal()\n\n\n\n\n\n\n\nData Summarisation and Creation\nNow, let’s examine how we can look at some summary statistics of the Hotwings variable in the beerwings_df data. For one sample, we can just use the summarise() function with whatever summary metrics we want to compute:\n\nbeerwings_df |&gt;\n  summarise(xbar = mean(Hotwings),\n            sd = sd(Hotwings),\n            n = n())\n\nIf we want to compare summary statistics for each level of a categorical variable, we can first group_by() that variable:\n\n# Two samples\nbeerwings_df |&gt;\n  group_by(Gender) |&gt;\n  summarise(xbar = mean(Hotwings),\n            sd = sd(Hotwings),\n            n = n())\n\nFinally, though this is not a data summary function, we can use filter() if we want to keep only certain rows in the data set. For example, if we want to get rid of any people who did not consume any Beer, we can use:\n\nbeerwings_onlybeer &lt;- beerwings_df |&gt; filter(Beer &gt; 0)\n\nExercise. The Girls2004 data is also in the resample R package, containing data on 80 newborn girls born in the state of Wyoming. Construct a set of side-by-side boxplots that explore the association between whether or not the mother was a Smoker (Smoker) with the Weight variable.\n\ngirls2004_df &lt;- Girls2004 |&gt; as_tibble() \n\nExercise. Again with the Wyoming girls data, obtain grouped summary statistics on Weight for girls in each Smoker group, including the mean weight, standard deviation of weight, and the number of girls in each Smoker group.\nCreating a Data Set with tibble()\n\nSuppose we need to enter our own data into R. As long as the sample size is relatively small (small enough that you can type things in manually without it being too much of a pain), we can create a data frame object using the tibble() function. For example, on the Stat 113 First Day survey, we ask students how long (in hours) it takes them to travel from home to SLU. Here are 6 responses: 6, 3.5, 0.4, 2.5, 12, 6.\nWe can make a data frame with those values:\n\nstat113_df &lt;- tibble(Travel = c(6, 3.5, 0.4, 2.5, 12, 6))\nstat113_df\n\n# A tibble: 6 × 1\n  Travel\n   &lt;dbl&gt;\n1    6  \n2    3.5\n3    0.4\n4    2.5\n5   12  \n6    6  \n\n\nIn the code, stat113_df is the name of the data frame while Travel is the name of the variable within that data frame.\nInstead of entering in raw data, we can also simulate data and put that simulated data into a data frame. For example, let’s convince ourselves that small samples from Normal populations don’t always look “Normal” by simulating a small sample of normally distributed data:\n\nfakedata &lt;- tibble(Normals = rnorm(n = 14, 15, 4))\n\nggplot(data = fakedata, aes(x = Normals)) + \n  geom_boxplot(fill = \"coral\") +\n  scale_y_continuous(labels = NULL) +\n  theme(axis.ticks.y = element_blank()) +\n  theme_minimal()\n\n\n\n\n\n\nggplot(data = fakedata, aes(x = Normals)) + \n  geom_histogram(fill = \"coral\", colour = \"coral4\", bins = 10) +\n  theme_minimal()\n\n\n\n\n\n\n\nExercise. Rerun the simulation code above a few times. What do you notice about the boxplots and histograms that you are generating?\nExercise. Rerun the simulation code above a few times, but change the sample size (\\(n\\)) from 14 to 1000. Now what do you notice about the boxplots and histograms that you are generating?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "conf-int.html#lab-3.2-conceptual-confidence-intervals",
    "href": "conf-int.html#lab-3.2-conceptual-confidence-intervals",
    "title": "3  Confidence Intervals",
    "section": "Lab 3.2: Conceptual Confidence Intervals",
    "text": "Lab 3.2: Conceptual Confidence Intervals\nThe primary purpose of this lab is to explore what the concept of “confidence” really means. To do so, we will construct confidence intervals first for a population proportion (\\(p\\)) and then for a mean (\\(\\mu\\)) using the “one-sample t” confidence interval formula.\n\nlibrary(resample)\nlibrary(tidyverse)\n\nOne Sample Proportion (CI for \\(p\\))\nSomething that you likely did in STAT 113 is use an app to investigate the “meaning of confidence.” We will revisit that idea here by exploring the sampling distribution of the sample proportion. Suppose that we have a sample size of \\(n = 50\\) and our true population proportion is \\(p = 0.25\\). Click on the “Confidence Interval” tab of the following app https://stlawu.shinyapps.io/samp_dist_conf_int/ and change the population proportion to be 0.25 and the sample size to be 50.\nExercise. What does each dot on the plot represent in this setting?\nExercise. Drag the slider to be approximately equal to the value 1.96 * sqrt(0.25 * (1 - 0.25) / 50) = 0.12). What proportion of the confidence intervals cover the true proportion of \\(p = 0.25\\)? Does that make sense?\nExercise. Which of the \\(\\hat{p}\\)’s seem to be “missing” the target of \\(p = 0.25\\)? Does that make sense?\nExercise. If you were to take a sample and, by chance, end up with an \\(\\hat{p}\\) and resulting interval that “misses” the target of \\(p = 0.25\\), why couldn’t you just toss that sample out and take a different sample?\nExercise. To generate a sample proportion from a population with a true proportion of success \\(p\\) and a certain sample size \\(n\\), we can use the following code. In the code what does phat represent on the app that you’ve been working with? How would you modify the code to create the entire graph shown in the app? (You do not need to actually modify the code).\n\nn &lt;- 50   # sample size\np &lt;- 0.25  # population proportion\n  \nx &lt;- rbinom(1, n, p) # randomly generate number of successes for the sample\n\n## number of successes divided by sample size\nphat &lt;- x / n\nphat\n\nOne Sample t (CI for \\(\\mu\\))\nIf we were to repeatedly generate random samples from a population and use those samples to construct (1 - \\(\\alpha\\))% confidence intervals, the coverage rate is defined as the fraction of those intervals that actually contain (capture) the parameter.\nIn the code below, we explore the average width and the coverage rate of confidence intervals for \\(\\mu\\) using the “standard” one-sample t formula. To start, let’s generate a single sample of size \\(n = 5\\) from a population that is normally distributed with mean \\(\\mu = 10\\) and standard deviation \\(\\sigma = 5\\) and then subsequently generate a single 95% confidence interval for the mean \\(\\mu\\) with that sample.\n\ngenerate_onesamp_cis &lt;- function(n, mu, sigma, alpha) {\n  \n  ## generate a single sample (one of nsim data sets)\n  x &lt;- rnorm(n, mu, sigma)\n  \n  ## compute the bounds of the ci\n  point_est &lt;- mean(x)\n  lb &lt;- point_est - qt(1 - alpha/2, df = n - 1) * sd(x) / sqrt(n)\n  ub &lt;- point_est + qt(1 - alpha/2, df = n - 1) * sd(x) / sqrt(n)\n  \n  ## put everything into a tibble\n  out_df &lt;- tibble(point_est, lb, ub)\n  \n  return(out_df)\n}\n\n\n## define parameters to use in our function\nn &lt;- 5   # sample size\nmu &lt;- 10     # true mean\nsigma &lt;- 5    # true standard deviation\nalpha &lt;- 0.05  # used to construct 1-alpha CI (how much area should be in the tails)\n\n## generate one sample and one ci\ngenerate_onesamp_cis(n = n, mu = mu, sigma = sigma, alpha = alpha)\n\n# A tibble: 1 × 3\n  point_est    lb    ub\n      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      12.2  9.05  15.3\n\n\nBut, if we want to explore the coverage rate and average interval width, we need to simulate many confidence intervals. Below, we map() through our function nsim times and bind the results together into a data frame at the end:\n\nnsim &lt;- 1000  # the number of simulated CIs to create\n\nmany_ci_df &lt;- map(1:nsim,\n                  \\(i) generate_onesamp_cis(n = n, mu = mu,\n                                            sigma = sigma,\n                                            alpha = alpha)) |&gt;\n  bind_rows()\nmany_ci_df\n\n# A tibble: 1,000 × 3\n   point_est     lb    ub\n       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1     12.9   7.73  18.1 \n 2      4.82  0.433  9.21\n 3      8.24  1.33  15.1 \n 4     10.7   7.68  13.8 \n 5     11.3   6.91  15.6 \n 6     11.0   6.85  15.1 \n 7     11.8   5.93  17.8 \n 8      5.78  1.76   9.79\n 9     12.7  11.2   14.1 \n10     15.6   9.76  21.5 \n# ℹ 990 more rows\n\n\nFinally, since we are interested in average interval width and coverage rate, we can create variables for the width of each confidence interval and for whether or not each interval “covers” the true mean mu:\n\nmany_ci_df &lt;- many_ci_df |&gt; mutate(ci_width = ub - lb,\n                                   ci_cover_ind = if_else(mu &gt; lb & mu &lt; ub,\n                                                          true = 1, \n                                                          false = 0))\n\nAnd we can then summarise() to get the average width and the coverage rate:\n\nmany_ci_df |&gt; summarise(avg_width = mean(ci_width),\n                        coverage_rate = mean(ci_cover_ind))\n\n# A tibble: 1 × 2\n  avg_width coverage_rate\n      &lt;dbl&gt;         &lt;dbl&gt;\n1      11.9         0.962\n\n\nExercise. Suppose that you increase the value of sigma in the code above and obtain new values for the avg_width and for coverage_rate. How do you expect each of these quantities to change with the new sigma?\nExercise. Suppose that you increase the value of mu in the code above and obtain new values for the avg_width and for coverage_rate. How do you expect each of these quantities to change with the new mu?\nExercise. Suppose that you increase the value of n in the code above and obtain new values for the avg_width and for coverage_rate. How do you expect each of these quantities to change with the new n?\nExercise. Suppose that you increase the value alpha in the code above and obtain new values for the avg_width and for coverage_rate. How do you expect each of these quantities to change with the new alpha?\n\nAs part of your mini-project for this section, you will explore what happens to “confidence” when assumptions are broken.\n\n\n\n\nTwo Sample Inference\nRecall from STAT 113 a couple of t procedures for generating confidence intervals:\n\nmatched pairs (if the two populations were not independent)\n“standard” two-sample t-test (assuming the populations are independent and have equal variances).\n\nAnd, a third one that you may or may not have seen in STAT 113 is the two-sample t-test that does not assume equal variances, called a “Welch’s two sample t-test”:\n\nWelch’s two sample t-test (assuming the populations are independent but relaxing the assumption that the populations have equal variances).\n\nExercise. Which of the following study designs should be analyzed as a matched-pairs design?\n\na sample of first-years and a sample of seniors are taken and we measure the number of alcoholic drinks each student had in the past month.\nwe take a random sample of students and measure how quickly they can complete a Sudoku puzzle without a dog in the room and then again with a dog in the room.\nfor 100 textbooks, we obtain the price of each book on Amazon and the price of each book at the bookstore.\nwe randomly select 100 textbooks and obtain their bookstore price and then we randomly select 100 textbooks and obtain their amazon price.\n\nExercise. Consider the third and fourth study designs in the previous exercise on textbooks. Which study design do you think will yield a more narrow confidence interval for the difference in mean textbook price?\n\nNext, we suppose that we have two populations and that we are interested in constructing a confidence interval for the difference in population means, \\(\\mu_1 - \\mu_2\\). To do so, we will not assume that the underlying variances of each population are equal and will instead use The Welch-Satterthwaite approximation to degrees of freedom for the \\(t^*\\) value to create the confidence interval.\n\nn1 &lt;- 15         # size of first sample\nmu1 &lt;- 20        # mean of first population\nsigma1 &lt;- 5      # standard deviation of first population\n\nn2 &lt;- 15         # size of second sample\nmu2 &lt;- 15        # mean of second population\nsigma2 &lt;- 5      # standard deviation of second population\n\nx &lt;- rnorm(n1, mu1, sigma1)       # generate sample 1 from Population 1\ny &lt;- rnorm(n2, mu2, sigma2)       # generate sample 2 from Population 2\n\nvarest1 &lt;- var(x)\nvarest2 &lt;- var(y)\n\nA &lt;- varest1 / n1\nB &lt;- varest2 / n2\n\nnumerator &lt;- (A + B) ^2\ndenominator &lt;- A^2 / (n1 - 1) + B^2 / (n2 - 1)\n\nwelchdf &lt;- numerator / denominator\nwelchdf\n\nExercise. Use the Welch-Satterthwaite approximation to find a 90% confidence interval for the difference in average hotwings consumed by males and the average hotwings consumed by females using a two-sample t formula that does not assume equal variance in the two populations.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "conf-int.html#lab-3.3-bootstrap-confidence-intervals",
    "href": "conf-int.html#lab-3.3-bootstrap-confidence-intervals",
    "title": "3  Confidence Intervals",
    "section": "Lab 3.3: Bootstrap Confidence Intervals",
    "text": "Lab 3.3: Bootstrap Confidence Intervals\nThe purpose of this lab is to construct bootstrap confidence intervals for a population mean, a population proportion, and for a difference in population means. To start, we construct a bootstrap confidence interval for a population mean.\n\nlibrary(resample)\nlibrary(tidyverse)\n\nBootstrap CI for a Population Mean\nBelow, the number of hours of exercise per week for a random sample of Stat 113 students are provided.\n\nlibrary(tidyverse)\nstat113_ex &lt;- tibble(Exercise = c(12, 3, 4, 10, 8, 17, 15, 5, 8, 10, 8,\n                                  25, 1, 15, 2, 14, 10, 8, 6, 14, 5, 6,\n                                  12, 3))\n\n# for demonstrating danger of bootstrapping with small sample sizes\n#stat113_ex = tibble(Exercise = c(25, 1, 2, 4, 0, 3, 0))\n\nBefore constructing any confidence interval, we should create a plot of the data and obtain the sample mean:\n\nggplot(data = stat113_ex, aes(x = Exercise)) +\n  geom_histogram(colour = \"black\", fill = \"white\", bins = 10) +\n  theme_minimal()\n\n\n\n\n\n\nmean(stat113_ex$Exercise) # sample mean\n\n[1] 9.208333\n\n\nNext, we create the bootstrap distribution of sample means and make a histogram of that distribution. For this example, we generate 1000 bootstrap samples. The function below outputs one bootstrap mean from a single bootstrap sample:\n\ngenerate_one_bootmean &lt;- function() {\n  ## put exercise variable into a vector\n  exercise_vec &lt;- stat113_ex |&gt; pull(Exercise)\n  \n  ## sample the exercise data with replacement\n  boot_samp &lt;- sample(exercise_vec, size = length(exercise_vec),\n                      replace = TRUE)\n  \n  boot_mean &lt;- mean(boot_samp)\n  \n  return(boot_mean)\n}\n\ngenerate_one_bootmean()\n\nWe can then map over the function to obtain B bootstrap means:\n\nB &lt;- 2000\nbootmean_vec &lt;- map_dbl(1:B, \\(i) generate_one_bootmean())\n\nWith our 2000 bootstrap means, we can construct a plot of the bootstrap distribution. This distribution should be somewhat centered at the sample mean.\n\nbootmean_df &lt;- tibble(bootmean_vec)\nggplot(data = bootmean_df, aes(x = bootmean_vec)) +\n  geom_histogram(colour = \"black\", fill = \"mediumseagreen\", bins = 14) +\n  geom_vline(xintercept = mean(stat113_ex$Exercise),\n             colour = \"grey\", linewidth = 2) +\n  theme_minimal()\n\n\n\n\n\n\n\nWe can also compute some quantities of interest that we discussed in class:\n\n## mean of bootstrap distribution (should be close to our statistic)\nmean(bootmean_vec)\n\n## Bootstrap SE\nsd(bootmean_vec)\n\n# bootstrap estimate of bias\nbias &lt;- mean(bootmean_vec) - mean(stat113_ex$Exercise)\nbias\n\n# what percent of the BS variation is due to bias?\nabs(bias) / sd(bootmean_vec)\n\n## Percentile Bootstrap confidence intervals\n# 90% CI\nquantile(bootmean_vec, c(0.05, 0.95))\n# 95% CI\nquantile(bootmean_vec, c(0.025, 0.975))\n\nExercise. Interpret the bootstrapped confidence interval for the mean \\(\\mu\\) in context of the problem.\nExercise. Use the formula derived in class to compute a 95% confidence interval for the mean \\(\\mu\\). How closely does the result match with the bootstrap confidence interval?\n\nBootstrap CI for a Population Proportion\nIn a random sample of 588 adults, 16.67% reported that key lime pie is their favorite kind of pie (only 16.67%….key lime is the GOAT of pies). Construct a 95% Bootstrap percentile confidence interval for the proportion of all adults that have key lime as their favorite pie.\n\n## create a data frame where a 1 corresponds to a person who\n## chose key lime pie while a 0 corresponds to a person who\n## chose anything else other than key lime pie\n\nn &lt;- 588\np_hat &lt;- 0.1667\npie_df &lt;- tibble(key_lime_fav = c(rep(1, round(n * p_hat)),\n                                  rep(0, n - round(n * p_hat))))\n\n## sample proportion (double check)\nmean(pie_df$key_lime_fav)\n\n[1] 0.1666667\n\n\nFirst, we write a function to obtain a single bootstrap proportion from a single bootstrap sample:\n\ngenerate_one_bootprop &lt;- function() {\n  ## put exercise variable into a vector\n  pie_vec &lt;- pie_df |&gt; pull(key_lime_fav)\n  \n  ## sample the exercise data with replacement\n  boot_samp &lt;- sample(pie_vec, size = length(pie_vec),\n                      replace = TRUE)\n  \n  boot_prop &lt;- mean(boot_samp)\n  \n  return(boot_prop)\n}\n\ngenerate_one_bootprop()\n\n[1] 0.1547619\n\n\nWe can then map over the function to obtain B bootstrap proportions and put these bootstrap proportions into a data frame:\n\nB &lt;- 5000\nbootprop_vec &lt;- map_dbl(1:B, \\(i) generate_one_bootprop())\n\nbootprop_df &lt;- tibble(bootprop_vec)\n\nExercise. Construct a histogram of the bootstrap sample proportions, adding in a vertical line for the sample proportion.\nExercise. Compute quantities of interest to help construct a percentile confidence interval for the true proportion. You should compute: the center of the bootstrap distribution, the bootstrap standard error, the bootstrap estimate of bias, the percent of the boostrap variation that is due to bias, a 90% percentile-based confidence interval for the true proportion, and a 95% percentile-based confidence interval for the true proportion.\nExercise. Interpret the 90% confidence interval in context of the problem.\nExercise. Use the large-sample approximation formula based on the asymptotic distribution of the MLE that we derived in class to compute a 90% confidence interval for \\(p\\). How does the interval compare to the 90% bootstrap confidence interval?\n\nBootstrap CI’s with Two (Independent) Samples\nFinally, we construct a bootstrap confidence interval using two independent random samples. We are interested in two different quantities here: the difference in population means and the ratio of population means. To do so, we use the flight data, which has information on flight delays from a sample of United Airlines flights (UA) and a sample of American Airlines flights (AA). We are interested in if either of these airlines has a higher average delay than the other.\nFirst, we obtain some summary statistics and make a plot of the data:\n\nlibrary(resampledata)\ndelay_df &lt;- FlightDelays |&gt; as_tibble()\n## set.seed(13617)  # 50100 for bias illustration\n\ndelay_df |&gt; group_by(Carrier) |&gt;\n  summarise(n = n(),\n            xbar = mean(Delay),\n            sd = sd(Delay))\n\n# A tibble: 2 × 4\n  Carrier     n  xbar    sd\n  &lt;fct&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 AA       2906  10.1  40.1\n2 UA       1123  16.0  45.1\n\nggplot(delay_df,\n       aes(x = Carrier, y = Delay)) + \n  geom_boxplot(fill = \"steelblue\") +\n  theme_minimal()\n\n\n\n\n\n\n\nOur sample statistic for the difference in means and for the ratio of means can be calculated with:\n\ndelays_aa &lt;- delay_df |&gt; filter(Carrier == \"AA\")\ndelays_ua &lt;- delay_df |&gt; filter(Carrier == \"UA\")\n\ndiffmeans &lt;- mean(delays_aa$Delay) - mean(delays_ua$Delay) # our sample statistic (diff. in means)\nratiomeans &lt;- mean(delays_aa$Delay) / mean(delays_ua$Delay) # our sample statistic (ratio of means)\n\nThe code below creates a function that generates either the boostrap difference in means or the bootstrap ratio of means from a single bootstrap sample:\n\ngenerate_one_boot &lt;- function(statistic = \"diff\") {\n  ## statistic can also be \"ratio\"\n  \n  ## put exercise variable into a vector\n  aa_vec &lt;- delays_aa |&gt; pull(Delay)\n  ua_vec &lt;- delays_ua |&gt; pull(Delay)\n  \n  \n  ## FILL IN MISSING PIECES\n\n  boot_samp_aa &lt;- sample(aa_vec, size = length(aa_vec), replace = TRUE)\n\n  ## fill in piece to obtain one bootstrap sample mean for ua flights\n  \n  if (statistic == \"diff\") {\n    \n    ## fill in piece to compute the difference in sample means\n    \n    return(boot_diff)\n    \n  } else if (statistic == \"ratio\") {\n    \n    ## fill in piece to compute the ratio of sample means\n    \n    return(boot_ratio)\n  }\n  \n}\n\nExercise. Using this function, we can obtain the bootstrap distribution of differences and the bootstrap distribution of ratios. Use the previous code to construct the histograms of these two bootstrap distributions, overlaying the sample statistics for each onto their appropriate bootstrap distributions.\nI’ve provided code to generate the bootstrap distribution of differences in means but you will need to adjust this to also create the bootstrap distribution for the ratio.\n\nB &lt;- 5000\nbootdiff_vec &lt;- map_dbl(1:B, \\(i) generate_one_boot(statistic = \"diff\"))\n\nbootdiff_df &lt;- tibble(bootdiff_vec)\n\nggplot(data = bootdiff_df, aes(x = bootdiff_vec)) +\n  geom_histogram(colour = \"black\", fill = \"mediumseagreen\", bins = 14) +\n  geom_vline(xintercept = diffmeans,\n             colour = \"grey\", linewidth = 2) +\n  theme_minimal()\n\nExercise. Compute relevant quantities of interest to help create a 90% percentile-based bootstrap confidence interval for the true mean difference in delay times and the true mean ratio of delay times.\nExercise. Interpret your two bootstrap confidence intervals in context of the problem.\nExercise. Use a Welch’s t-test to compute a 90% confidence interval for the true mean difference in delay times. Why do you think this result does not match very closely with the bootstrap confidence interval for the mean difference?\nExercise. Use a Welch’s t-test to compute a 90% confidence interval for the true mean ratio of delay times.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "conf-int.html#mini-project-3-simulation-to-investigate-confidence-intervals",
    "href": "conf-int.html#mini-project-3-simulation-to-investigate-confidence-intervals",
    "title": "3  Confidence Intervals",
    "section": "Mini Project 3: Simulation to Investigate Confidence Intervals",
    "text": "Mini Project 3: Simulation to Investigate Confidence Intervals\nThe confidence intervals we have discussed in class each have associated assumptions in order for us to use them correctly. But, what exactly happens if one of the assumptions is violated? Why is a violated assumption ‘bad’ anyway? In this mini-project, you will investigate what happens to interval width and coverage rate if an assumption is violated for the asymptotic confidence interval for a population proportion.\nProject Description\nAI Usage: You may not use generative AI for this project in any way.\nCollaboration: For this project, you may work with a self-contained group of 3. Keep in mind that you may not work with the same person on more than one mini-project (so, if you worked with a student on the first mini-project as a partner or in a small group, you may not work with that person on this project). Finally, if working with a partner or in a group of 3, you may submit the same code and the same table of results, but your write-up (both the short summary of your methods and your findings summary) must be written individually.\nStatement of Integrity: At the top of your submission, copy and paste the following statement and type your name, certifying that you have followed all AI and collaboration rules for this mini-project.\n“I have followed all rules for collaboration for this project, and I have not used generative AI on this project.”\n\nStep 1. Decide on 3 different sample sizes (\\(n\\): small, medium, large) and 2 different population proportions (\\(p\\): close to 0.5 and far from 0.5). Thus, the number of settings you will investigate is 6. The confidence level you should use is 90% for this project. Note: the “large sample” assumption for the asymptotic confidence interval that we discussed in class must be violated in at least two of the six settings and must hold for at least two of the six settings.\nStep 2. I recommend starting with one of the settings where the “large sample” assumption holds. For this setting, construct at least 5000 sample proportions and 5000 associated confidence intervals.\nStep 3. From your 5000 confidence intervals, calculate both (1) the average interval width and (2) the coverage rate.\nStep 4. Repeat Steps 2 and 3 for the other 5 settings, recording the average interval width and the coverage rate for each of these other 5 settings.\nWhat to Submit: You should submit a typed write-up of your simulation results as well as your code. There are a few possible formats you might use to submit this mini-project:\n\na rendered .qmd file (either to .html, .pdf, or .docx) that includes your write-up, results, and code (so echo: true in the global YAML).\na Word file that contains your results and write-up and a separate .qmd file that has all of your code. Note that, for this option, your code should still be organized and easy to follow.\n\nIn your submission, you should include:\n\nexplicit calculations for whether or not the “large sample assumption” we discussed in class for the asymptotic confidence interval holds for each of the six settings.\na table that summarises the coverage rates and average widths for the cases you considered. Code for the table generated below is provided.\nthree paragraphs summarising your findings in your simulation.\n\n\nTable of Results\n\n\n\n\n\n\n\n\n\n\n$n = $\n$n = $\n$n = $\n\n\n\n\\(p = xxx\\)\nCoverage Rate\n\n\n\n\n\n\\(p = yyy\\)\nCoverage Rate\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p = xxx\\)\nAverage Width\n\n\n\n\n\n\\(p = yyy\\)\nAverage Width\n\n\n\n\n\n\n\n|  |         | $n = $ | $n = $ | $n = $ |\n|:----:|:-----------------:|:-------------:|:------------:|:------------:|\n| $p = xxx$   | Coverage Rate       |        |       |              |\n| $p = yyy$   | Coverage Rate       |        |       |              |\n|    |                     |               |              |              |\n| $p = xxx$    | Average Width        |       |       |              |\n| $p = yyy$    | Average Width        |       |       |              |\n\n\n: Table of Results {.striped .hover}",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Confidence Intervals</span>"
    ]
  },
  {
    "objectID": "bayesian.html",
    "href": "bayesian.html",
    "title": "4  Bayesian Statistics",
    "section": "",
    "text": "Lab 4.1: Introduction to Bayesian: Binomial Data\nIn this lab, we will analyze binomial data in a Bayesian framework with a couple of different prior distributions for \\(p\\). The first prior for \\(p\\) will be a non-informative prior while the second prior for \\(p\\) will be based on “expert” (your!) opinion prior to the analysis.\nTo start, consider your own prowess at the popular game “flip cup” and your (self-assessed) probability of successfully flipping the cup so that it’s upside-down on a single trial. Use the app at http://shiny.stlawu.edu:3838/sample-apps/stat325/distplot/ to drag the sliders around until you settle on a reasonable informative prior distribution for the probability that you successfully flip a cup from right-side-up to upside-down (note that you should not use a non-informative prior here). In general:\nWrite down the parameters you will use for your informative prior of you successfully flipping a cup.\nIn comparison, we will also use a Beta(1, 1) = Uniform(0, 1) prior distribution for \\(p\\). This is a non-informative prior.\nAfter you have settled on your informative prior, use the code below to construct a plot of both the informative prior and the non-informative prior.\nlibrary(tidyverse)\nps &lt;- seq(0, 1, length.out = 1000)\n\ninformative_alpha &lt;- 2 ## CHANGE THIS TO YOUR ALPHA\ninformative_beta &lt;- 4  ## CHANGE THIS TO YOUR BETA\n\nnoninformative_alpha &lt;- 1\nnoninformative_beta &lt;- 1\n\ninformative_prior &lt;- dbeta(ps, informative_alpha,\n                           informative_beta)\nnoninformative_prior &lt;- dbeta(ps,\n                              noninformative_alpha, noninformative_beta)\n\nprior_plot &lt;- tibble(ps, informative_prior, noninformative_prior) |&gt;\n  pivot_longer(2:3, names_to = \"prior_type\", values_to = \"density\")\n\nggplot(data = prior_plot, aes(x = ps, y = density, colour = prior_type)) +\n  geom_line() +\n  scale_colour_viridis_d(end = 0.9) +\n  theme_minimal() +\n  labs(x = \"p\")\nExercise. With our informative prior and our non-informative prior, we will now collect some data to include in our Bayesian analysis. After you collect data, derive the posterior distribution of \\(p\\) using both the non-informative prior and the informative prior. Then, adjust the code below to produce a plot of your two posterior distributions.\nlibrary(tidyverse)\nps &lt;- seq(0, 1, length.out = 1000)\n\ninformative_alpha &lt;- 2 ## CHANGE THIS TO YOUR ALPHA\ninformative_beta &lt;- 4  ## CHANGE THIS TO YOUR BETA\n\nnoninformative_alpha &lt;- 1\nnoninformative_beta &lt;- 1\n\ninformative_prior &lt;- dbeta(ps, informative_alpha,\n                           informative_beta)\nnoninformative_prior &lt;- dbeta(ps,\n                              noninformative_alpha, noninformative_beta)\n\n## CHANGE THESE\ninformative_alpha_post &lt;- 4\ninformative_beta_post &lt;- 4\ninformative_post &lt;- dbeta(ps, informative_alpha_post,\n                          informative_beta_post)\n\n## CHANGE THESE\nnoninformative_alpha_post &lt;- 2\nnoninformative_beta_post &lt;- 2\nnoninformative_post &lt;- dbeta(ps, noninformative_alpha_post,\n                             noninformative_beta_post)\n\nplot_df &lt;- tibble(ps, informative_prior, noninformative_prior,\n                     informative_post, noninformative_post) |&gt;\n  pivot_longer(2:5, names_to = \"distribution\", values_to = \"density\") |&gt;\n  separate(distribution, into = c(\"prior_type\", \"distribution\"))\n\nggplot(data = plot_df, aes(x = ps, y = density, colour = prior_type,\n                           linetype = distribution)) +\n  geom_line() +\n  scale_colour_viridis_d(end = 0.9) +\n  theme_minimal() +\n  labs(x = \"p\")\nExercise. For each posterior, compute the posterior mean (the Bayes estimate).\nExercise. For each posterior, compute a 95% credible interval for \\(p\\).\nExercise. Interpret one of the 95% credible intervals in context of the problem.\nExercise. Consider the results from the analysis with your informative prior. Is the mean of the informative prior higher or lower than the mean of the posterior distribution? Why do you think that is?\nExercise. The informative prior that you used was very subjective, based on your own knowledge and thoughts of how well you think you can play flip cup. What do you think can be done to limit the subjectivity of this prior?\nExercise. Suppose that, instead of choosing an informative prior via the app, you instead have a target mean for \\(p\\) of 0.40 and a target standard deviation for \\(p\\) of 0.05. Your goal is to find parameters of the Beta distribution that satisfy (approximately) these constraints and use those parameters in the prior. Can you modify the code below to figure out good parameters for this prior?\ntarget_mean &lt;- ____\n\nalphas &lt;- seq(0.1, 60, length.out = 500)\nbetas &lt;- \n\nparam_df &lt;- tibble(alphas, betas)\nparam_df &lt;- param_df |&gt; mutate(vars = \n                    ____)\n\n\ntarget_var &lt;- ____\n\nparam_df &lt;- param_df |&gt; mutate(dist_to_target = abs(vars - target_var))\nparam_df\n\nparam_df |&gt; filter(dist_to_target == min(dist_to_target))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "bayesian.html#lab-4.1-introduction-to-bayesian-binomial-data",
    "href": "bayesian.html#lab-4.1-introduction-to-bayesian-binomial-data",
    "title": "4  Bayesian Statistics",
    "section": "",
    "text": "increasing \\(\\alpha\\) will shift the distribution to the right.\nincreasing \\(\\beta\\) will shift the distribution to the left.\nincreasing both will give a distribution with less variability.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "bayesian.html#lab-4.2-more-bayesian-poisson-data",
    "href": "bayesian.html#lab-4.2-more-bayesian-poisson-data",
    "title": "4  Bayesian Statistics",
    "section": "Lab 4.2: More Bayesian: Poisson Data",
    "text": "Lab 4.2: More Bayesian: Poisson Data\n\nlibrary(tidyverse)\n\nRecall from probability that we discussed using a Poisson model to model the number of goals that the St. Lawrence women’s hockey team scores in a game. In that class, we assumed that we knew the value of \\(\\lambda\\) in that probability model and we computed a few quantities of interest under that assumption.\nUsually, however, \\(\\lambda\\) must be estimated (in a frequentist analysis) using data, or, in a Bayesian analysis, we can provide a probability model for \\(\\lambda\\) itself that is either non-informative or informed by expert opinion or prior data.\nSuppose that the women’s hockey coach says that he thinks their team scores about 3 goals per game, on average. When pressed for how “sure” they are of that answer and to give a reasonable range for what values that goal scoring rate is, they reply that they are not quite sure. But, they know that they are almost certain that the scoring rate is no less than 2 goals per game, on average.\nAs discussed in class, the conjugate prior for Poisson data is the Gamma distribution, which can be used to model \\(\\lambda\\).\nExercise. Using the coach’s information, come up with an informative prior for \\(\\lambda\\) with the Gamma distribution. Note that we will have some decisions to make in how to use the coach’s information to come up with an informative prior!\nA relatively non-informative prior for \\(\\lambda\\) is a Gamma distribution with very small values for both \\(\\alpha\\) and \\(k\\). Note that, for the gamma distribution, I am replacing \\(\\lambda\\) with \\(k\\), so that we are not working with two different \\(\\lambda\\)’s (since the Poisson also has a parameter called \\(\\lambda\\)). Using \\(\\alpha = 0.001\\) and \\(k = 0.001\\), construct a plot of a relatively non-informative prior for \\(\\lambda\\) using the code below.\n\nalpha &lt;- 0.001\nk &lt;- 0.001\nlambda_grid &lt;- seq(0, 5, length.out = 1000)\ngamma_density &lt;- dgamma(lambda_grid, shape = alpha, rate = k)\n\ngamma_plot &lt;- tibble(lambda_grid, gamma_density)\n\nggplot(data = gamma_plot, aes(x = lambda_grid, y = gamma_density)) +\n  geom_line() +\n  theme_minimal()\n\n\n\n\n\n\n\nExercise. Based on the plot of the non-informative prior, it’s a little difficult to see why this prior is non-informative. However, using what we derived as the posterior distribution for \\(\\lambda\\), construct an argument for why a prior of \\(\\alpha = 0.001\\) and \\(k = 0.001\\) is a non-informative prior.\nExercise. Using the code above, construct a plot of the informative prior we derived earlier.\nNow suppose that we collect data from the women’s hockey team this season to update both our non-informative prior and our informative prior with data to obtain two posterior distributions for the goal rate.\nThe code below pulls in data from the season:\n\nlibrary(rvest)\nurl &lt;- \"https://saintsathletics.com/sports/womens-ice-hockey/stats/2024-25\"\ntab &lt;- read_html(url) |&gt; \n  html_nodes(\"table\")\nhockey_stats &lt;- tab[[6]] |&gt; html_table(header = FALSE) \n\nnewnames &lt;- paste(hockey_stats[1, ], hockey_stats[2, ])\ngoals &lt;- hockey_stats |&gt; set_names(newnames) |&gt;\n  slice(-1, -2) |&gt;\n  mutate(`Shots G` = as.numeric(`Shots G`)) |&gt;\n  filter(`Shots G` &lt;= 20) |&gt; ## filter out the totals (hoping that the women\n## never scored more than 20 goals in one game!!)\n  pull(`Shots G`) |&gt; as.numeric()\ngoals\n\nExercise. Using this data and the posterior that we computed in class, figure out the posterior distribution for the goal rate with the non-informative prior and with the informative prior.\nExercise. Use the code below to construct a plot of each of the posterior distributions.\n\n## CHANGE THESE!!\nalpha &lt;- 1\nk &lt;- 1\nlambda_grid &lt;- seq(0, 5, length.out = 1000)\ngamma_density_noninf &lt;- dgamma(lambda_grid, shape = alpha, rate = k)\n\n## CHANGE THESE!!\nalpha2 &lt;- 2\nk2 &lt;- 2\ngamma_density_inf &lt;- dgamma(lambda_grid, shape = alpha2, rate = k2)\n\ngamma_plot &lt;- tibble(lambda_grid, gamma_density_noninf, gamma_density_inf) |&gt;\n  pivot_longer(starts_with(\"gamma\"), names_to = \"distribution\", values_to = \"density\")\n\nggplot(data = gamma_plot, aes(x = lambda_grid, y = density)) +\n  geom_line(aes(colour = distribution)) +\n  scale_colour_viridis_d(end = 0.9) +\n  theme_minimal() +\n  labs(x = \"lambda\")\n\nExercise. What are the mean of the prior distribution, the mean of the data, and the mean of the posterior distribution. Which of these numbers must be in between the other two? Conceptually, why does that make sense?\nExercise. With each posterior, compute a 95% credible interval for \\(\\lambda\\), the rate that the women’s hockey team scores goals.\nExercise. Interpret one of the credible intervals in context of the problem.\nExercise. Think back to the data that we used for this example. What assumptions have we made to complete this analysis? Can you think of ways that we might relax these assumptions?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "bayesian.html#mini-project-4-bayesian-analysis",
    "href": "bayesian.html#mini-project-4-bayesian-analysis",
    "title": "4  Bayesian Statistics",
    "section": "Mini Project 4: Bayesian Analysis",
    "text": "Mini Project 4: Bayesian Analysis\nProject Introduction\nAI Usage: You may not use generative AI for this project in any way.\nCollaboration: For this project, you may work with a self-contained group of 3. Keep in mind that you may not work with the same person on more than one mini-project (so, if you worked with a student on the first or third mini-project as a partner or in a small group, you may not work with that person on this project). Finally, if working with a partner or in a group of 3, you may submit the same code and the same results/visuals, but your write-ups must be written individually.\nStatement of Integrity: At the top of your submission, copy and paste the following statement and type your name, certifying that you have followed all AI and collaboration rules for this mini-project.\n“I have followed all rules for collaboration for this project, and I have not used generative AI on this project.”\n\nRafael Nadal is arguably the greatest men’s clay-court tennis player ever to play the game. In this mini-project, you analyze the probability that Nadal wins a point on his own serve against his primary rival, Novak Djokovic, at the French Open (the most prestigious clay court tournament in the world).\nPriors\nBefore we look at some data, we will consider a few possible prior distributions for the probability that Nadal wins a point on his own serve against Djokovic:\n\nnon-informative prior for this probability.\nan informative prior based on a clay-court match the two played in the previous year. In that match, Nadal won 46 out of 66 points on his own serve. The standard error of this estimate is 0.05657.\nan informative prior based on a sports announcer, who claims that they think Nadal wins about 75% of the points on his serve against Djokovic. They are also “almost sure” that Nadal wins no less than 70% of his points on serve against Djokovic.\n\nHere is some code that we briefly did in class for the Gamma-Poisson hockey scoring example that might help you write code to generate one of the priors mentioned above.\n\n## trying to get a mean of 3 and a probability\n## that lambda is less than 2 equal to 0.02\nalphas &lt;- seq(0.01, 100, length.out = 2000) \nks &lt;- alphas / 3\n\ntarget_prob &lt;- 0.02\nprob_less_2 &lt;- pgamma(2, alphas, ks)\n\ntibble(alphas, ks, prob_less_2) |&gt;\n  mutate(close_to_target = abs(prob_less_2 - target_prob)) |&gt;\n  filter(close_to_target == min(close_to_target))\n\n# A tibble: 1 × 4\n  alphas    ks prob_less_2 close_to_target\n   &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;           &lt;dbl&gt;\n1   31.0  10.3      0.0200     0.000000718\n\n\nConstruct a single graph that shows all three of these priors. Note that, for both of the informative priors, there is some subjectivity with how you are going to use the information given to construct an appropriate prior for \\(p\\), the probability that Nadal wins a point on serve against Djokovic. In other words, for the two informative priors, there is not necessarily a “correct” answer for how to approach creating them. Instead, you will be assessed on your logic and reason in coming up with the two informative priors.\nData\nNow, we want to use the 2020 French Open data to update our prior for the probability that Nadal wins a point on serve. In that tournament, the two players played in the final. In that final, Nadal served 84 points and won 56 of those points.\nUpdate each of your three priors with this data and make a plot of the three different posterior distributions of \\(p\\).\nAdditionally, for each of the three posteriors, report the posterior mean and 90% credible intervals for \\(p\\).\nReport\nFor this mini-project, you should submit a report that includes the following:\n\nan introduction to the question of interest that you are answering for this project as well as an overview of how you will be answering this question.\ntyped work justifying the decisions you made to create the two informative priors. What did you assume when you made those priors?\nthe graph of the three priors and the graph of the three posteriors, along with any work needed to obtain the posteriors, the posterior means, and the 90% credible intervals\na comparison of the three posteriors.\n\nThey should be a bit different from each other: why?\nIf you had to choose one to use, which one would you choose here and why?\nThe variance of each posterior should be different. Why do you think one posterior has a lower variance than the other two?\n\n\na brief conclusion of what you found in this mini-project.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Bayesian Statistics</span>"
    ]
  },
  {
    "objectID": "hyp-test.html",
    "href": "hyp-test.html",
    "title": "5  Hypothesis Testing",
    "section": "",
    "text": "Lab 5.1: Permutation Tests\nIn this lab, we use permutation tests to assess whether there is evidence that the mean delay times of two different airlines are different and whether there is evidence that completing a difficult task with a dog in the room lowers stress level, on average.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "hyp-test.html#lab-5.1-permutation-tests",
    "href": "hyp-test.html#lab-5.1-permutation-tests",
    "title": "5  Hypothesis Testing",
    "section": "",
    "text": "Example 1: Flight Data\nConsider again the flight delay data. Here, we will consider whether or not there is statistical evidence that the mean delay of United Airlines is different than the mean delay of American Airlines.\nRecall that, for a permutation test, we do not need to assume that the underlying populations follow a normal distribution. However, if we are interested in testing a difference in means, we do need to assume that the populations have the same variance and the same shape (but perhaps may have a different center). Note that, if we have a randomized experiment, then these assumptions can be relaxed.\nFirst, we obtain some summary statistics and make a plot of the data:\n\nlibrary(tidyverse)\nlibrary(resampledata)\ndelay_df &lt;- FlightDelays |&gt; as_tibble() |&gt;\n  select(Carrier, Delay, everything())\n## set.seed(13617)  # 50100 for bias illustration\n\ndelay_df |&gt; group_by(Carrier) |&gt;\n  summarise(n = n(),\n            xbar = mean(Delay),\n            sd = sd(Delay))\n\n# A tibble: 2 × 4\n  Carrier     n  xbar    sd\n  &lt;fct&gt;   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 AA       2906  10.1  40.1\n2 UA       1123  16.0  45.1\n\nggplot(delay_df,\n       aes(x = Carrier, y = Delay)) + \n  geom_boxplot(fill = \"steelblue\") +\n  theme_minimal()\n\n\n\n\n\n\n\nWe next store the difference in sample means as a value called teststat and each of the sample sizes as n_a and n_u:\n\nteststat &lt;- delay_df |&gt; group_by(Carrier) |&gt;\n  summarise(mean_delay = mean(Delay)) |&gt;\n  pull(mean_delay) |&gt;\n  diff()\n## teststat is united delay mean minus american airlines mean\n\nUnder the null hypothesis, the distribution of delays is identical for american and united airlines. To reshuffle the delay values randomly across both airlines we can use the code below:\n\ndelay_df |&gt;\n  mutate(delay_perm = sample(Delay, size = nrow(delay_df), replace = FALSE)) |&gt;\n  relocate(delay_perm)\n\n# A tibble: 4,029 × 11\n   delay_perm Carrier Delay    ID FlightNo Destination DepartTime Day   Month\n        &lt;int&gt; &lt;fct&gt;   &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;fct&gt;       &lt;fct&gt;      &lt;fct&gt; &lt;fct&gt;\n 1         -1 UA         -1     1      403 DEN         4-8am      Fri   May  \n 2         -7 UA        102     2      405 DEN         8-Noon     Fri   May  \n 3        108 UA          4     3      409 DEN         4-8pm      Fri   May  \n 4          0 UA         -2     4      511 ORD         8-Noon     Fri   May  \n 5        142 UA         -3     5      667 ORD         4-8am      Fri   May  \n 6        -10 UA          0     6      669 ORD         4-8am      Fri   May  \n 7         80 UA         -5     7      673 ORD         8-Noon     Fri   May  \n 8         51 UA          0     8      677 ORD         8-Noon     Fri   May  \n 9         -1 UA         10     9      679 ORD         Noon-4pm   Fri   May  \n10         -6 UA         60    10      681 ORD         Noon-4pm   Fri   May  \n# ℹ 4,019 more rows\n# ℹ 2 more variables: FlightLength &lt;int&gt;, Delayed30 &lt;fct&gt;\n\n\nRerun the previous code chunk a few times to see a different permutations of the Delay variable.\nWith one permutation, we want to recalculate the difference in means:\n\ndelay_df |&gt;\n  mutate(delay_perm = sample(Delay, size = nrow(delay_df), replace = FALSE)) |&gt;\n  relocate(delay_perm) |&gt;\n  group_by(Carrier) |&gt;\n  summarise(mean_delay_perm = mean(delay_perm)) |&gt;\n  pull(mean_delay_perm) |&gt;\n  diff()\n\n[1] 0.6177111\n\n\nRerun the code chunk above a few times to get a few different mean differences under different permutations. The big idea is that a large number of these mean differences will form the null distribution for the difference in sample means (if there really is no difference in the underlying population distributions).\nSo, let’s wrap that above code in a function, and then iterate over that function a large number of times to obtain our null distribution:\n\nget_delay_perm_diff &lt;- function() {\n  delay_df |&gt;\n    mutate(delay_perm = sample(Delay, size = nrow(delay_df), replace = FALSE)) |&gt;\n    relocate(delay_perm) |&gt;\n    group_by(Carrier) |&gt;\n    summarise(mean_delay_perm = mean(delay_perm)) |&gt;\n    pull(mean_delay_perm) |&gt;\n    diff()\n}\n\nn_perm &lt;- 5000\ndiff_means &lt;- map_dbl(1:n_perm, \\(i) get_delay_perm_diff())\nnull_df &lt;- tibble(diff_means)\n\nggplot(data = null_df, aes(x = diff_means)) +\n  geom_histogram(colour = \"orange4\", fill = \"orange2\", bins = 15) +\n  theme_minimal()\n\n\n\n\n\n\n\nExercise. Write a 1-2 sentence interpretation of what this null distribution means in context of the problem.\nExercise. Write a 1-2 sentence explanation on what the code above is doing.\nNow, let’s add where our test statistic from our data is on the graph:\n\nggplot(data = null_df, aes(x = diff_means)) +\n  geom_histogram(colour = \"orange4\", fill = \"orange2\", bins = 15) +\n  geom_vline(xintercept = teststat, colour = \"grey75\") +\n  theme_minimal()\n\n\n\n\n\n\n\nExercise. Before explicitly calculating a p-value, assess visually whether a p-value for this hypothesis test will be relatively large or relatively small.\nNow, let’s explicitly compute a conservative p-value for the test:\n\n(sum(diff_means &gt; abs(teststat)) + sum(diff_means &lt; -abs(teststat)) + 1) / (n_perm + 1)\n\n[1] 0.00039992\n\n\nExercise. What is the alternative hypothesis that the p-value is testing?\nExercise. What is the purpose of the + 1 in the code above?\nExercise. Why are there two different summations in the code above to get the p-value?\nExercise. Write a conclusion in context of the problem for this hypothesis test.\nExample 2: Stress Levels\nMany of you took our probability exams with the adorable Mipha providing moral support throughout the exam. There has actually been formal research assessing whether being in the presence of a dog can have beneficial effects for people. In one such study, researchers recruited 30 women who were self-proclaimed dog lovers. They randomly assigned 15 women to a stressful task alone (control: C) and 15 women to do a stressful task with a pet dog present (pet: P). The response variable is heart rate during the task, with higher heart rates presumed to mean that the there was more stress during the task.\nUse the code below to read in the data and do some brief data exploration:\n\nlibrary(tidyverse)\nstress_df &lt;- read_csv(\"https://raw.githubusercontent.com/highamm/stat326_labs/master/data/stress_dog.csv\")\n\nRows: 30 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): group\ndbl (1): rate\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nData Exploration:\n\nggplot(data = stress_df, aes(x = group, y = rate, fill = group)) +\n  geom_boxplot(outlier.shape = 8) +\n  theme_minimal() +\n  scale_fill_viridis_d(begin = 0.4, end = 0.9) +\n  guides(fill = \"none\")\n\n\n\n\n\n\nstress_df |&gt; group_by(group) |&gt;\n  summarise(mean = mean(rate),\n            n = n())\n\n# A tibble: 2 × 3\n  group  mean     n\n  &lt;chr&gt; &lt;dbl&gt; &lt;int&gt;\n1 C      82.5    15\n2 P      73.5    15\n\n\nExercise. What do you find from your data exploration plot? What are the observed sample mean heart rates for each group?\n\nTest Statistic:\n\n# From our summary statistics\nteststat &lt;- stress_df |&gt; group_by(group) |&gt;\n  summarise(mean = mean(rate),\n            n = n()) |&gt;\n  pull(mean) |&gt;\n  diff()\n## Pet minus Control\nteststat\n\n[1] -9.041\n\n\nExercise: Modify the following code to create the null distribution for a test that the mean heart rate is different in each of the two groups.\n\nget_stress_perm_diff &lt;- function() {\n  stress_df |&gt;\n    mutate(rate_perm = sample(____,\n                                size = nrow(____), replace = FALSE)) |&gt;\n    relocate(rate_perm) |&gt;\n    group_by(_______) |&gt;\n    summarise(mean_rate_perm = mean(rate_perm)) |&gt;\n    pull(mean_rate_perm) |&gt;\n    diff()\n}\nget_rate_perm_diff()\n\nn_perm &lt;- 5000\ndiff_means &lt;- map_dbl(1:n_perm, \\(i) get_rate_perm_diff())\nnull_df &lt;- tibble(diff_means)\n\nggplot(data = null_df, aes(x = diff_means)) +\n  geom_histogram(colour = \"skyblue4\", fill = \"skyblue1\", bins = 15) +\n  ## add test stat to null dist\n  geom_vline(xintercept = teststat, colour = \"purple\") +\n  theme_minimal()\n\nExercise. Calculate a p-value for the test.\nExercise. Write a conclusion in context of the problem for this hypothesis test.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "hyp-test.html#lab-5.2-asymptotic-lrts-in-practice",
    "href": "hyp-test.html#lab-5.2-asymptotic-lrts-in-practice",
    "title": "5  Hypothesis Testing",
    "section": "Lab 5.2: Asymptotic LRTs in Practice",
    "text": "Lab 5.2: Asymptotic LRTs in Practice\n\nIn this lab, we will see an example of how an asymptotic likelihood ratio test is used in practice.\nLogistic Regression Example\nIf you took STAT 213, recall the logistic regression model that you used in that course:\n\\(Y_i \\sim \\text{Bernoulli}(p_i)\\), where each \\(Y_i\\) is independent of all other \\(Y_j\\) but the \\(Y_i\\) are not identically distributed. Instead, each \\(Y_i\\) is allowed to have its own probability of success, \\(p_i\\), which can be modeled as:\n\\[\n\\text{E}(Y_i) = p_i = \\frac{\\text{exp}(\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_k x_{ki})}{1 + \\text{exp}(\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_k x_{ki})},\n\\]\nwhere \\(x_{1i}, x_{2i}, \\ldots, x_{ki}\\) are possible predictor variables for the probability of success.\nRecall: For what type of response variable was logistic regression an appropriate model?\nRecall: What values is the quantity \\(\\frac{\\text{exp}(\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_k x_{ki})}{1 + \\text{exp}(\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + ... + \\beta_k x_{ki})}\\) bounded by?\nConsider the following data set on survival of passengers aboard the Titanic.\n\nlibrary(tidyverse)\n\ntitanic_df &lt;- read_csv(\"https://raw.githubusercontent.com/highamm/stat326_labs/master/data/titanic.csv\",\n                       col_types = list(Pclass = col_factor())) |&gt;\n  filter(!is.na(Age) & !is.na(Sex)) |&gt;\n  mutate(Pclass = fct_recode(Pclass,\n                             \"1st\" = \"1\",\n                             \"2nd\" = \"2\",\n                             \"3rd\" = \"3\"))\ntitanic_df |&gt; slice(1:3) |&gt;\n  dplyr::select(Survived, Pclass, Name, Sex, Age) |&gt;\n  pander::pander()\n\n\n\n\n\n\n\n\n\n\nSurvived\nPclass\nName\nSex\nAge\n\n\n\n0\n3rd\nBraund, Mr. Owen Harris\nmale\n22\n\n\n1\n1st\nCumings, Mrs. John Bradley (Florence Briggs Thayer)\nfemale\n38\n\n\n1\n3rd\nHeikkinen, Miss. Laina\nfemale\n26\n\n\n\n\n\nExercise. Suppose that we want to build a logistic regression model with Survived (a 1 is survived and 0 is died) as the response variable and Age and Sex as predictors. We want to test whether there is an association of Age and whether or not a passenger survived (after accounting for the effects of Sex.\n\nWrite out the logistic regression model with Age and Sex as predictors.\nWrite the null hypothesis for our hypothesis test.\nWrite both the “null model” and the “alternative model.”\nWhat is the value of maximum likelihood under the null model? We will start by writing the likelihood function, assuming that the null model is true.\nWhat is the maximum likelihood under the alternative model? We will start by writing the likelihood function, assuming that the alternative model is true.\n\nNow, we have reached a point where the calculations have become a bit too unweildy. So, we will let R calculate the maximum likelihoods of these two models. R only has functionality to return the log likelihood using the logLik() function from a fitted model, so, we will backtransform the log likelihood using exp() to obtain the maximum likelihood for each family of models.\nFirst, for the “null model” that does not include Age:\n\ntitanic_null &lt;- glm(Survived ~ Sex,\n                    data = titanic_df, family = \"binomial\")\nlogLik(titanic_null) |&gt; exp() |&gt; as.numeric()\n\n[1] 9.716759e-164\n\n\nNow, we obtain the value of the likelihood maximized under the alternative model (that does include Age):\n\ntitanic_alt &lt;- glm(Survived ~ Sex + Age,\n                    data = titanic_df, family = \"binomial\")\nlogLik(titanic_alt) |&gt; exp() |&gt; as.numeric()\n\n[1] 1.409022e-163\n\n\n\nUsing these values for the maximum likelihoods of each model, calculate the test statistic for the asymptotic likelihood ratio test.\nUsing the test statistic, calculate the p-value for the test.\nExamine the output from the alternative model below. Can you locate the p-value we just calculated?\n\n\nbroom::tidy(titanic_alt)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  1.28      0.230       5.55  2.87e- 8\n2 Sexmale     -2.47      0.185     -13.3   2.26e-40\n3 Age         -0.00543   0.00631    -0.860 3.90e- 1\n\n\n\nsummary(titanic_alt)\n\n\nCall:\nglm(formula = Survived ~ Sex + Age, family = \"binomial\", data = titanic_df)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  1.277273   0.230169   5.549 2.87e-08 ***\nSexmale     -2.465920   0.185384 -13.302  &lt; 2e-16 ***\nAge         -0.005426   0.006310  -0.860     0.39    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 964.52  on 713  degrees of freedom\nResidual deviance: 749.96  on 711  degrees of freedom\nAIC: 755.96\n\nNumber of Fisher Scoring iterations: 4",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "hyp-test.html#lab-5.3-empirical-power",
    "href": "hyp-test.html#lab-5.3-empirical-power",
    "title": "5  Hypothesis Testing",
    "section": "Lab 5.3: Empirical Power",
    "text": "Lab 5.3: Empirical Power\nWe have seen some examples of how to compute power analytically, but, as the statistical test we use gets more complex, computing power becomes much more tedious (and sometimes is not even possible to compute exactly). In these scenarios, people often use empirical power to approximate the power of a test for a few different sample sizes or for a few different values of the alternative hypothesis.\nIn this lab, we will suppose that a researcher wants to assess whether there is evidence that a new drug helps to lower blood pressure. Note that “clinical trials” is a branch of statistics that deals with how to analyze medical data. Do note that clinical trials are more complex than what we are dealing with here, often with many different “phases” and specialized types of analysis.\nRecruiting subjects in clinical trials is quite expensive! So the researcher would like to limit costs as much as possible, while still recruiting enough subjects to be able to assess whether the drug is effective.\nIn particular, the researcher can apply for funding to either recruit 50 participants (25 for a group that receives the new drug and 25 for a group that receives a placebo), to recruit 200 participants (100 in each group), or to recruit 500 participants (250 in each group).\nFinally, the researcher wants to be fairly certain that they do not falsely reject the null hypothesis so they will only reject the null hypothesis if they get a p-value that is less than or equal to \\(\\alpha = 0.01\\), and they would like to conduct a two-sided test that assumes the population variances are equal.\nExercise. What else do we need to know from the researcher to conduct a power analysis? There are actually a couple of things that we need!\nExercise. What are the null and alternative hypotheses for this test?\n\nOnce we have that information, use the following code to compute empirical power.\n\nlibrary(tidyverse)\ndelta &lt;- 5\nsigma &lt;- 20\nn &lt;- 10 ## sample size for one group \n\ncompute_twosamp_pval &lt;- function(delta, sigma, n) {\n  samp1 &lt;- rnorm(n, 0, sigma)\n  samp2 &lt;- rnorm(n, 0 + delta, sigma)\n  \n  test_out &lt;- t.test(samp1, samp2, var.equal = TRUE)\n  p_val &lt;- test_out$p.value\n  \n  return(p_val)\n}\n\ncompute_twosamp_pval(delta = delta,\n                   sigma = sigma,\n                   n = n)\n\n[1] 0.510824\n\n\nExercise. What does delta represent in the code above?\nExercise. We do not know the true mean blood pressures \\(\\mu_1\\) and \\(\\mu_2\\) in the population. So why are we “allowed” to set one of the true means to be 0 in the code above?\nExercise. If we were to repeatedly run the function many times and we were to set delta to be equal to 0, what proportion of p-values would you expect to be less than 0.01?\nNow, to calculate empirical power, we need to map through the function we wrote a large number of times, recording a p-value for the test each time we run the function.\n\nn_sim &lt;- 10000\np_vals &lt;- map_dbl(1:n_sim, \\(i) compute_twosamp_pval(delta = delta, sigma = sigma, n = n))\n\nAnd, we will reject the null hypothesis if the p-value we observe from one of the simulations is less than alpha:\n\nemp_power_df &lt;- tibble(p_vals) |&gt;\n  mutate(reject = if_else(p_vals &lt;= 0.01,\n                          true = 1, false = 0))\nemp_power_df\n\n# A tibble: 10,000 × 2\n   p_vals reject\n    &lt;dbl&gt;  &lt;dbl&gt;\n 1 0.407       0\n 2 0.0870      0\n 3 0.739       0\n 4 0.478       0\n 5 0.519       0\n 6 0.139       0\n 7 0.0752      0\n 8 0.881       0\n 9 0.101       0\n10 0.155       0\n# ℹ 9,990 more rows\n\n\nExercise. How would you calculate empirical power from the previous data frame? (you do not have to answer this in terms of specific R code but should instead give the idea of how you would calculate empirical power here).\nExercise Before conducting the power analysis, what do you expect to happen to the power as we increase the sample size? What about as we increase the (absolute) value of delta? What about if we increase alpha?\nExercise. Before conducting the analysis, it might also be nice to check and make sure that our function is working as we would expect. Run the code below. Is the empirical power what you expect? Why or why not?\n\np_vals_0_25 &lt;- map_dbl(1:n_sim,\n                       \\(i) compute_twosamp_pval(delta = 0,\n                                               sigma = sigma, n = 25))\n\np_val_df &lt;- tibble(p_vals_0_25) |&gt;\n  mutate(across(everything(), ~ if_else(.x &lt;= 0.01,\n                                        true = 1, false = 0)))\np_val_df\np_val_df |&gt;\n  summarise(across(everything(), ~ mean(.x)))\n\nExercise. Modify the mapping code above to use the values that the researcher was most interested in. You should have 6 different settings that you need to map through (3 sample sizes times 2 values of delta). Additionally, you can use the code immediately above this exercise (with across()) to calculate the empirical power for all 6 settings at once.\nExercise. Write a one paragraph summary of your results to the researcher. What should their sample size be? Does the choice of sample size that you recommend depend on the value of delta?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "hyp-test.html#mini-project-5-advantages-and-drawbacks-of-using-p-values",
    "href": "hyp-test.html#mini-project-5-advantages-and-drawbacks-of-using-p-values",
    "title": "5  Hypothesis Testing",
    "section": "Mini Project 5: Advantages and Drawbacks of Using p-values",
    "text": "Mini Project 5: Advantages and Drawbacks of Using p-values\nAI Usage: You may not use generative AI for this project in any way.\nCollaboration: For this project, you may work with a self-contained group of 3. Keep in mind that you may not work with the same person on more than one mini-project (so, if you worked with a student on the first, third, or fourth mini-projects as a partner or in a small group, you may not work with that person on this project). Finally, if working with a partner or in a group of 3, your write-ups must be distinct and written individually (so you can chat with your group about what you might say, but you should never copy a group member’s response).\nStatement of Integrity: At the top of your submission, copy and paste the following statement and type your name, certifying that you have followed all AI and collaboration rules for this mini-project.\n“All work presented is my own, and I have followed all rules for collaboration. I have not used generative AI on this project.”\n\nFor this final mini-project, you will read an editorial published in The American Statistician and respond to the questions below. You will find a pdf of the editorial on Canvas.\nFirst, read through the first six sections of the editorial titled Moving to a World Beyond ‘p &lt; 0.05’ by Wasserstein, Schirm, and Lazar published in The American Statistician in 2019 as the introduction to a special issue about p-values. I strongly encourage you to read the first six sections at least twice before you attempt to respond to the questions that appear below. This mini-project will be graded, primarily, on how thoughtfully you respond to these questions.\nSubmission: Upload your typed responses to these questions to the assignment in Canvas by the deadline.\nQuestions:\n\nTowards the end of Section 1, the authors say “As ‘statistical significance’ is used less, statistical thinking will be used more.” Elaborate on what you think the authors mean. Give some examples of what you think embodies “statistical thinking.”\nSection 2, third paragraph: The authors state “A label of statistical significance adds nothing to what is already conveyed by the value of \\(p\\); in fact, this dichotomization of p-values makes matters worse.” Elaborate on what you think the authors means.\nSection 2, end of first column: The authors state “For the integrity of scientific publishing and research dissemination, therefore, whether a p-value passes any arbitrary threshold should not be considered at all when deciding which results to present or highlight.” Do you agree or disagree? How should it be decided which results to present/highlight in scientific publishing?\nSection 3, end of page 2: The authors state “The statistical community has not yet converged on a simple paradigm for the use of statistical inference in scientific research – and in fact it may never do so. A one-size-fits-all approach to statistical inference is an inappropriate expectation.” Do you agree or disagree? Explain.\nSection 3.2: The authors note that they are envisioning “a sort of ‘statistical thoughtfulness’.” What do you think “statistical thoughtfulness” means? What are some ways to demonstrate “statistical thoughtfulness” in an analysis?\nSection 3.2.4: A few of the authors of papers in this special issue argue that some of the terminology used in statistics, such as “significance” and “confidence” can be misleading, and they propose the use of “compatibility” instead. What you do you think they believe the problem is? Do you agree or disagree (that there is a problem and that changing the name will help)?\nFind a quote or point that really strikes you (i.e., made you think). What is the quote (and tell me where to find it), and why does it stand out to you?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "6  Portfolio",
    "section": "",
    "text": "WORK IN PROGRESS\nInstead of a traditional final exam, you are tasked with writing a short portfolio on concepts we have discussed throughout the semester and then subsequently taking an in-class assessment on certain components of the portfolio during our final exam time.\nThe final portfolio should consist of the following pieces.\n\nConceptual Understanding of Topics (30 points)\nAI Usage: You may use generative AI if you would like, but you must clearly state any and all prompts given to AI as well as what you ended up using from AI’s response into your own. Failure to do so will result in a 0 on the entire portfolio.\nOur course was broken up into 5 sections: Sampling Distributions, Estimation, Confidence Intervals, Bayesian Statistics, and Hypothesis Testing. Write a single paragraph for each of the following five prompts, which ask you to think about the overall purpose of each section.\nEach question is worth 6 points.\n\nSection 1 (Sampling Distributions). Throughout most of the section on sampling distributions, we supposed that we knew a probability model that could generate data and that we knew the values of the parameters in that probability model (e.g., \\(\\mu = 10\\), \\(\\sigma = 2\\) in a normal probability model). Given that in practice, we rarely know the true values of the parameters in a model, what do you think the overall purpose of this section was? In other words, why complete this section if we rarely actually know the values of parameters?\nSection 2 (Estimation). In the section on estimation, we used a few different methods (method of moments, maximum likelihood estimation) to derive estimators for parameters in probability models using data. Something that we emphasized is the idea of a “bias variance trade-off.” Explain what the bias variance trade-off is. In your explanation, you should address what bias is and what variance is by explaining what would happen if you applied an estimator with high bias to repeated (thousands of) samples of data and what would happen if you applied an estimator with high variance to repeated (thousands of) samples of data.\nSection 3 (Confidence Intervals). We spent some time in class discussing what is meant by “95% confidence.” Now, consider the simple linear regression model \\(Y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\\), where \\(\\epsilon_i\\) are iid \\(\\text{N}(0, \\sigma^2)\\) random variables. Suppose that you use obtain a 95% confidence interval for \\(\\beta_1\\), the slope parameter in the model using R, Python, or other statistical software. Explain what is meant by “95% confidence” in this setting (perhaps reviewing Lab 3.2).\nSection 4 (Bayesian). What are the primary differences (conceptually) between working in a “frequentist” framework (all stats you would have likely seen up to this section) and a “Bayesian” framework?\nSection 5. Consider again the simple linear regression model \\(Y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\\), where \\(\\epsilon_i\\) are iid \\(\\text{N}(0, \\sigma^2)\\) random variables, and suppose that your friend collects some data to conduct a hypothesis test \\(H_0: \\beta_1 = 0\\) vs. \\(H_a: \\beta_1 \\neq 0\\). They correctly obtain a p-value of 0.994 from the test and conclude: “My p-value is very large and quite close to 1, so the null hypothesis is extremely likely to be true.” Explain what is wrong with your friend’s conclusion.\n\n\n\nReflection (20 points)\nAI Usage: You may not use generative AI for this reflection at all. I want to know what your thoughts are here! Use of AI will result in a 0 on the entire portfolio.\nEach prompt is worth 5 points. For each, 4 points will be awarded for a complete answer while 5 points will be awarded for a thoughtful and sophisticated answer.\n\nReflect on your overall experience in this class by describing an interesting idea that you learned, why it was interesting to you, and what it tells you about practicing statistics.\nWhich assessment (homework assignment, recap task, mini-project, or in-class assessment) do you feel you learned the most from? Explain what you learned from this assessment and/or why the assessment was valuable to you.\nWhat was a concept you learned in this course that you hope you remember 5 years from now? Why is it important that you remember this concept?\nWhat statistical ideas are you curious to know more about as a result of taking this class? Try to give two examples and explain why you would like to know more about them.\n\n\n\nIn-Class Assessment (50 points)\nIn class during our final exam time, you will be prompted with 5 short “essay”-style questions that are based off of the prompts given in the “conceptual understanding” section of the portfolio. Note that the questions posed will not be exact verbatim matches to the five questions above, but they will be extremely similar.\nFor the in-class assessment, you may not use a cheat sheet (there will not be any formula or calculation style questions). You should be adequately prepared for this assessment if you understand each of the prompts given in the “Conceptual Understanding of Topics” section of the portfolio!\nYou will have the full 3 hours to complete the assessment, but I would expect the average time to complete it to be about 45 minutes.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Portfolio</span>"
    ]
  }
]